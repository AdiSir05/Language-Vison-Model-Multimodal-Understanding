{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision transformers bert-score evaluate tqdm matplotlib numpy sklearn evaluate rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EXN0rAtgrdQ5",
        "outputId": "c0d85f23-4f98-4150-87a9-e79b129f3c73"
      },
      "id": "EXN0rAtgrdQ5",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip models.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFB4i6bNsZAj",
        "outputId": "56b6623b-4a86-44e8-f428-cdb2b92cdc3a"
      },
      "id": "KFB4i6bNsZAj",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  models.zip\n",
            "   creating: models/\n",
            "  inflating: models/wm_stegastamp_decoder.pth  \n",
            "  inflating: models/wm_stegastamp_encoder.pth  \n",
            "  inflating: models/stegastamp_wm.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "Gi0w7Zmlrspf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "90804409-6d43-48ee-ee68-e882f32180e7"
      },
      "id": "Gi0w7Zmlrspf",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: data/images/train/000000157046.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000157046.jpg  \n",
            "  inflating: data/images/train/000000421455.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000421455.jpg  \n",
            "  inflating: data/images/train/000000525155.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000525155.jpg  \n",
            "  inflating: data/images/train/000000413395.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000413395.jpg  \n",
            "  inflating: data/images/train/000000579158.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000579158.jpg  \n",
            "  inflating: data/images/train/000000276024.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000276024.jpg  \n",
            "  inflating: data/images/train/000000077396.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000077396.jpg  \n",
            "  inflating: data/images/train/000000436883.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000436883.jpg  \n",
            "  inflating: data/images/train/000000419653.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000419653.jpg  \n",
            "  inflating: data/images/train/000000343706.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000343706.jpg  \n",
            "  inflating: data/images/train/000000325483.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000325483.jpg  \n",
            "  inflating: data/images/train/000000217425.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000217425.jpg  \n",
            "  inflating: data/images/train/000000312549.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000312549.jpg  \n",
            "  inflating: data/images/train/000000281447.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000281447.jpg  \n",
            "  inflating: data/images/train/000000500464.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500464.jpg  \n",
            "  inflating: data/images/train/000000241677.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000241677.jpg  \n",
            "  inflating: data/images/train/000000296649.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000296649.jpg  \n",
            "  inflating: data/images/train/000000312213.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000312213.jpg  \n",
            "  inflating: data/images/train/000000289741.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000289741.jpg  \n",
            "  inflating: data/images/train/000000406997.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000406997.jpg  \n",
            "  inflating: data/images/train/000000262938.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000262938.jpg  \n",
            "  inflating: data/images/train/000000415727.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000415727.jpg  \n",
            "  inflating: data/images/train/000000084752.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000084752.jpg  \n",
            "  inflating: data/images/train/000000186637.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186637.jpg  \n",
            "  inflating: data/images/train/000000013348.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000013348.jpg  \n",
            "  inflating: data/images/train/000000118209.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000118209.jpg  \n",
            "  inflating: data/images/train/000000140076.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000140076.jpg  \n",
            "  inflating: data/images/train/000000150265.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000150265.jpg  \n",
            "  inflating: data/images/train/000000393282.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000393282.jpg  \n",
            "  inflating: data/images/train/000000572555.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000572555.jpg  \n",
            "  inflating: data/images/train/000000311295.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000311295.jpg  \n",
            "  inflating: data/images/train/000000092124.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000092124.jpg  \n",
            "  inflating: data/images/train/000000105264.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000105264.jpg  \n",
            "  inflating: data/images/train/000000320706.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000320706.jpg  \n",
            "  inflating: data/images/train/000000563470.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000563470.jpg  \n",
            "  inflating: data/images/train/000000108026.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000108026.jpg  \n",
            "  inflating: data/images/train/000000289594.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000289594.jpg  \n",
            "  inflating: data/images/train/000000147725.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000147725.jpg  \n",
            "  inflating: data/images/train/000000261982.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000261982.jpg  \n",
            "  inflating: data/images/train/000000334767.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000334767.jpg  \n",
            "  inflating: data/images/train/000000057244.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000057244.jpg  \n",
            "  inflating: data/images/train/000000172946.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000172946.jpg  \n",
            "  inflating: data/images/train/000000388846.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000388846.jpg  \n",
            "  inflating: data/images/train/000000364636.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000364636.jpg  \n",
            "  inflating: data/images/train/000000509656.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000509656.jpg  \n",
            "  inflating: data/images/train/000000049091.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000049091.jpg  \n",
            "  inflating: data/images/train/000000559707.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000559707.jpg  \n",
            "  inflating: data/images/train/000000076261.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000076261.jpg  \n",
            "  inflating: data/images/train/000000184791.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000184791.jpg  \n",
            "  inflating: data/images/train/000000567825.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000567825.jpg  \n",
            "  inflating: data/images/train/000000322844.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000322844.jpg  \n",
            "  inflating: data/images/train/000000159282.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000159282.jpg  \n",
            "  inflating: data/images/train/000000403353.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000403353.jpg  \n",
            "  inflating: data/images/train/000000277689.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000277689.jpg  \n",
            "  inflating: data/images/train/000000246454.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000246454.jpg  \n",
            "  inflating: data/images/train/000000578093.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000578093.jpg  \n",
            "  inflating: data/images/train/000000554579.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000554579.jpg  \n",
            "  inflating: data/images/train/000000311518.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000311518.jpg  \n",
            "  inflating: data/images/train/000000516038.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000516038.jpg  \n",
            "  inflating: data/images/train/000000192871.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000192871.jpg  \n",
            "  inflating: data/images/train/000000216277.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000216277.jpg  \n",
            "  inflating: data/images/train/000000110721.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000110721.jpg  \n",
            "  inflating: data/images/train/000000232538.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000232538.jpg  \n",
            "  inflating: data/images/train/000000217948.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000217948.jpg  \n",
            "  inflating: data/images/train/000000102331.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000102331.jpg  \n",
            "  inflating: data/images/train/000000387383.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000387383.jpg  \n",
            "  inflating: data/images/train/000000054605.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000054605.jpg  \n",
            "  inflating: data/images/train/000000290833.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000290833.jpg  \n",
            "  inflating: data/images/train/000000315187.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000315187.jpg  \n",
            "  inflating: data/images/train/000000053624.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000053624.jpg  \n",
            "  inflating: data/images/train/000000366141.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000366141.jpg  \n",
            "  inflating: data/images/train/000000467776.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000467776.jpg  \n",
            "  inflating: data/images/train/000000374545.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000374545.jpg  \n",
            "  inflating: data/images/train/000000352582.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000352582.jpg  \n",
            "  inflating: data/images/train/000000575372.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000575372.jpg  \n",
            "  inflating: data/images/train/000000017714.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000017714.jpg  \n",
            "  inflating: data/images/train/000000374551.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000374551.jpg  \n",
            "  inflating: data/images/train/000000276434.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000276434.jpg  \n",
            "  inflating: data/images/train/000000474078.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000474078.jpg  \n",
            "  inflating: data/images/train/000000258911.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000258911.jpg  \n",
            "  inflating: data/images/train/000000140658.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000140658.jpg  \n",
            "  inflating: data/images/train/000000234607.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000234607.jpg  \n",
            "  inflating: data/images/train/000000034873.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000034873.jpg  \n",
            "  inflating: data/images/train/000000544811.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000544811.jpg  \n",
            "  inflating: data/images/train/000000417285.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000417285.jpg  \n",
            "  inflating: data/images/train/000000565607.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000565607.jpg  \n",
            "  inflating: data/images/train/000000348243.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000348243.jpg  \n",
            "  inflating: data/images/train/000000394328.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000394328.jpg  \n",
            "  inflating: data/images/train/000000440336.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000440336.jpg  \n",
            "  inflating: data/images/train/000000416170.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000416170.jpg  \n",
            "  inflating: data/images/train/000000305343.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000305343.jpg  \n",
            "  inflating: data/images/train/000000217753.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000217753.jpg  \n",
            "  inflating: data/images/train/000000092939.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000092939.jpg  \n",
            "  inflating: data/images/train/000000449312.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000449312.jpg  \n",
            "  inflating: data/images/train/000000564280.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000564280.jpg  \n",
            "  inflating: data/images/train/000000158956.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000158956.jpg  \n",
            "  inflating: data/images/train/000000578871.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000578871.jpg  \n",
            "  inflating: data/images/train/000000562197.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000562197.jpg  \n",
            "  inflating: data/images/train/000000100283.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000100283.jpg  \n",
            "  inflating: data/images/train/000000297147.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297147.jpg  \n",
            "  inflating: data/images/train/000000447465.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000447465.jpg  \n",
            "  inflating: data/images/train/000000195918.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000195918.jpg  \n",
            "  inflating: data/images/train/000000471869.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000471869.jpg  \n",
            "  inflating: data/images/train/000000458223.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000458223.jpg  \n",
            "  inflating: data/images/train/000000384661.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000384661.jpg  \n",
            "  inflating: data/images/train/000000119088.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000119088.jpg  \n",
            "  inflating: data/images/train/000000515445.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000515445.jpg  \n",
            "  inflating: data/images/train/000000021503.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000021503.jpg  \n",
            "  inflating: data/images/train/000000547854.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000547854.jpg  \n",
            "  inflating: data/images/train/000000521509.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000521509.jpg  \n",
            "  inflating: data/images/train/000000417911.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000417911.jpg  \n",
            "  inflating: data/images/train/000000574520.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000574520.jpg  \n",
            "  inflating: data/images/train/000000532575.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000532575.jpg  \n",
            "  inflating: data/images/train/000000472623.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000472623.jpg  \n",
            "  inflating: data/images/train/000000363207.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000363207.jpg  \n",
            "  inflating: data/images/train/000000000724.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000000724.jpg  \n",
            "  inflating: data/images/train/000000324158.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000324158.jpg  \n",
            "  inflating: data/images/train/000000132796.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000132796.jpg  \n",
            "  inflating: data/images/train/000000389812.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000389812.jpg  \n",
            "  inflating: data/images/train/000000419096.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000419096.jpg  \n",
            "  inflating: data/images/train/000000213086.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213086.jpg  \n",
            "  inflating: data/images/train/000000346905.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000346905.jpg  \n",
            "  inflating: data/images/train/000000569565.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000569565.jpg  \n",
            "  inflating: data/images/train/000000323151.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000323151.jpg  \n",
            "  inflating: data/images/train/000000071877.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000071877.jpg  \n",
            "  inflating: data/images/train/000000237118.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000237118.jpg  \n",
            "  inflating: data/images/train/000000011615.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000011615.jpg  \n",
            "  inflating: data/images/train/000000075393.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000075393.jpg  \n",
            "  inflating: data/images/train/000000150649.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000150649.jpg  \n",
            "  inflating: data/images/train/000000458790.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000458790.jpg  \n",
            "  inflating: data/images/train/000000511384.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000511384.jpg  \n",
            "  inflating: data/images/train/000000365886.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000365886.jpg  \n",
            "  inflating: data/images/train/000000175387.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000175387.jpg  \n",
            "  inflating: data/images/train/000000331569.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000331569.jpg  \n",
            "  inflating: data/images/train/000000211120.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000211120.jpg  \n",
            "  inflating: data/images/train/000000007088.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000007088.jpg  \n",
            "  inflating: data/images/train/000000300039.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000300039.jpg  \n",
            "  inflating: data/images/train/000000482275.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000482275.jpg  \n",
            "  inflating: data/images/train/000000396729.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000396729.jpg  \n",
            "  inflating: data/images/train/000000031248.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000031248.jpg  \n",
            "  inflating: data/images/train/000000397351.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000397351.jpg  \n",
            "  inflating: data/images/train/000000086582.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000086582.jpg  \n",
            "  inflating: data/images/train/000000568690.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000568690.jpg  \n",
            "  inflating: data/images/train/000000209753.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000209753.jpg  \n",
            "  inflating: data/images/train/000000298738.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000298738.jpg  \n",
            "  inflating: data/images/train/000000360097.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000360097.jpg  \n",
            "  inflating: data/images/train/000000508602.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000508602.jpg  \n",
            "  inflating: data/images/train/000000283318.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000283318.jpg  \n",
            "  inflating: data/images/train/000000356531.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000356531.jpg  \n",
            "  inflating: data/images/train/000000318138.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000318138.jpg  \n",
            "  inflating: data/images/train/000000209747.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000209747.jpg  \n",
            "  inflating: data/images/train/000000299355.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000299355.jpg  \n",
            "  inflating: data/images/train/000000070229.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000070229.jpg  \n",
            "  inflating: data/images/train/000000189698.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000189698.jpg  \n",
            "  inflating: data/images/train/000000324818.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000324818.jpg  \n",
            "  inflating: data/images/train/000000125572.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125572.jpg  \n",
            "  inflating: data/images/train/000000548555.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000548555.jpg  \n",
            "  inflating: data/images/train/000000286507.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000286507.jpg  \n",
            "  inflating: data/images/train/000000341058.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000341058.jpg  \n",
            "  inflating: data/images/train/000000096960.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000096960.jpg  \n",
            "  inflating: data/images/train/000000407524.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000407524.jpg  \n",
            "  inflating: data/images/train/000000237864.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000237864.jpg  \n",
            "  inflating: data/images/train/000000388258.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000388258.jpg  \n",
            "  inflating: data/images/train/000000188592.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000188592.jpg  \n",
            "  inflating: data/images/train/000000522940.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000522940.jpg  \n",
            "  inflating: data/images/train/000000316666.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000316666.jpg  \n",
            "  inflating: data/images/train/000000214703.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000214703.jpg  \n",
            "  inflating: data/images/train/000000256518.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000256518.jpg  \n",
            "  inflating: data/images/train/000000477955.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000477955.jpg  \n",
            "  inflating: data/images/train/000000383443.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000383443.jpg  \n",
            "  inflating: data/images/train/000000222299.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000222299.jpg  \n",
            "  inflating: data/images/train/000000392228.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000392228.jpg  \n",
            "  inflating: data/images/train/000000160012.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000160012.jpg  \n",
            "  inflating: data/images/train/000000025228.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000025228.jpg  \n",
            "  inflating: data/images/train/000000407518.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000407518.jpg  \n",
            "  inflating: data/images/train/000000321790.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000321790.jpg  \n",
            "  inflating: data/images/train/000000276804.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000276804.jpg  \n",
            "  inflating: data/images/train/000000173091.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000173091.jpg  \n",
            "  inflating: data/images/train/000000431727.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000431727.jpg  \n",
            "  inflating: data/images/train/000000176857.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000176857.jpg  \n",
            "  inflating: data/images/train/000000227478.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000227478.jpg  \n",
            "  inflating: data/images/train/000000196009.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000196009.jpg  \n",
            "  inflating: data/images/train/000000329455.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000329455.jpg  \n",
            "  inflating: data/images/train/000000203294.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000203294.jpg  \n",
            "  inflating: data/images/train/000000098018.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000098018.jpg  \n",
            "  inflating: data/images/train/000000259830.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000259830.jpg  \n",
            "  inflating: data/images/train/000000084431.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000084431.jpg  \n",
            "  inflating: data/images/train/000000466125.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000466125.jpg  \n",
            "  inflating: data/images/train/000000430377.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000430377.jpg  \n",
            "  inflating: data/images/train/000000408830.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000408830.jpg  \n",
            "  inflating: data/images/train/000000284106.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000284106.jpg  \n",
            "  inflating: data/images/train/000000541773.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000541773.jpg  \n",
            "  inflating: data/images/train/000000209222.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000209222.jpg  \n",
            "  inflating: data/images/train/000000500049.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500049.jpg  \n",
            "  inflating: data/images/train/000000192904.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000192904.jpg  \n",
            "  inflating: data/images/train/000000045090.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000045090.jpg  \n",
            "  inflating: data/images/train/000000163057.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000163057.jpg  \n",
            "  inflating: data/images/train/000000229858.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000229858.jpg  \n",
            "  inflating: data/images/train/000000530820.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000530820.jpg  \n",
            "  inflating: data/images/train/000000104782.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000104782.jpg  \n",
            "  inflating: data/images/train/000000306139.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000306139.jpg  \n",
            "  inflating: data/images/train/000000122745.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000122745.jpg  \n",
            "  inflating: data/images/train/000000306893.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000306893.jpg  \n",
            "  inflating: data/images/train/000000005477.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000005477.jpg  \n",
            "  inflating: data/images/train/000000262440.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000262440.jpg  \n",
            "  inflating: data/images/train/000000567011.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000567011.jpg  \n",
            "  inflating: data/images/train/000000122962.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000122962.jpg  \n",
            "  inflating: data/images/train/000000388927.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000388927.jpg  \n",
            "  inflating: data/images/train/000000345941.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000345941.jpg  \n",
            "  inflating: data/images/train/000000407083.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000407083.jpg  \n",
            "  inflating: data/images/train/000000013201.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000013201.jpg  \n",
            "  inflating: data/images/train/000000289393.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000289393.jpg  \n",
            "  inflating: data/images/train/000000090108.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000090108.jpg  \n",
            "  inflating: data/images/train/000000572408.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000572408.jpg  \n",
            "  inflating: data/images/train/000000548780.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000548780.jpg  \n",
            "  inflating: data/images/train/000000439623.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000439623.jpg  \n",
            "  inflating: data/images/train/000000390826.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000390826.jpg  \n",
            "  inflating: data/images/train/000000052507.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000052507.jpg  \n",
            "  inflating: data/images/train/000000193429.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000193429.jpg  \n",
            "  inflating: data/images/train/000000261161.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000261161.jpg  \n",
            "  inflating: data/images/train/000000407646.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000407646.jpg  \n",
            "  inflating: data/images/train/000000028452.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000028452.jpg  \n",
            "  inflating: data/images/train/000000394275.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000394275.jpg  \n",
            "  inflating: data/images/train/000000043581.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000043581.jpg  \n",
            "  inflating: data/images/train/000000036678.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000036678.jpg  \n",
            "  inflating: data/images/train/000000396338.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000396338.jpg  \n",
            "  inflating: data/images/train/000000255401.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000255401.jpg  \n",
            "  inflating: data/images/train/000000303653.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000303653.jpg  \n",
            "  inflating: data/images/train/000000313454.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000313454.jpg  \n",
            "  inflating: data/images/train/000000406570.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000406570.jpg  \n",
            "  inflating: data/images/train/000000504415.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000504415.jpg  \n",
            "  inflating: data/images/train/000000546626.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000546626.jpg  \n",
            "  inflating: data/images/train/000000509131.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000509131.jpg  \n",
            "  inflating: data/images/train/000000362520.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000362520.jpg  \n",
            "  inflating: data/images/train/000000005503.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000005503.jpg  \n",
            "  inflating: data/images/train/000000403385.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000403385.jpg  \n",
            "  inflating: data/images/train/000000066926.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000066926.jpg  \n",
            "  inflating: data/images/train/000000143556.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000143556.jpg  \n",
            "  inflating: data/images/train/000000560178.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000560178.jpg  \n",
            "  inflating: data/images/train/000000481386.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000481386.jpg  \n",
            "  inflating: data/images/train/000000564336.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000564336.jpg  \n",
            "  inflating: data/images/train/000000546829.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000546829.jpg  \n",
            "  inflating: data/images/train/000000540280.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000540280.jpg  \n",
            "  inflating: data/images/train/000000281693.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000281693.jpg  \n",
            "  inflating: data/images/train/000000448810.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000448810.jpg  \n",
            "  inflating: data/images/train/000000395180.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000395180.jpg  \n",
            "  inflating: data/images/train/000000281687.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000281687.jpg  \n",
            "  inflating: data/images/train/000000550939.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000550939.jpg  \n",
            "  inflating: data/images/train/000000335450.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000335450.jpg  \n",
            "  inflating: data/images/train/000000469174.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000469174.jpg  \n",
            "  inflating: data/images/train/000000202001.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000202001.jpg  \n",
            "  inflating: data/images/train/000000431848.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000431848.jpg  \n",
            "  inflating: data/images/train/000000557501.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000557501.jpg  \n",
            "  inflating: data/images/train/000000098839.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000098839.jpg  \n",
            "  inflating: data/images/train/000000299553.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000299553.jpg  \n",
            "  inflating: data/images/train/000000453001.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000453001.jpg  \n",
            "  inflating: data/images/train/000000211069.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000211069.jpg  \n",
            "  inflating: data/images/train/000000166259.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000166259.jpg  \n",
            "  inflating: data/images/train/000000198805.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000198805.jpg  \n",
            "  inflating: data/images/train/000000255165.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000255165.jpg  \n",
            "  inflating: data/images/train/000000514376.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000514376.jpg  \n",
            "  inflating: data/images/train/000000579818.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000579818.jpg  \n",
            "  inflating: data/images/train/000000313130.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000313130.jpg  \n",
            "  inflating: data/images/train/000000243075.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000243075.jpg  \n",
            "  inflating: data/images/train/000000223959.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000223959.jpg  \n",
            "  inflating: data/images/train/000000393056.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000393056.jpg  \n",
            "  inflating: data/images/train/000000307145.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000307145.jpg  \n",
            "  inflating: data/images/train/000000136334.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000136334.jpg  \n",
            "  inflating: data/images/train/000000177383.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000177383.jpg  \n",
            "  inflating: data/images/train/000000357941.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000357941.jpg  \n",
            "  inflating: data/images/train/000000255824.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000255824.jpg  \n",
            "  inflating: data/images/train/000000143998.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000143998.jpg  \n",
            "  inflating: data/images/train/000000343934.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000343934.jpg  \n",
            "  inflating: data/images/train/000000209829.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000209829.jpg  \n",
            "  inflating: data/images/train/000000009891.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000009891.jpg  \n",
            "  inflating: data/images/train/000000549930.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000549930.jpg  \n",
            "  inflating: data/images/train/000000570169.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000570169.jpg  \n",
            "  inflating: data/images/train/000000064499.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000064499.jpg  \n",
            "  inflating: data/images/train/000000326174.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000326174.jpg  \n",
            "  inflating: data/images/train/000000013177.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000013177.jpg  \n",
            "  inflating: data/images/train/000000011760.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000011760.jpg  \n",
            "  inflating: data/images/train/000000531135.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000531135.jpg  \n",
            "  inflating: data/images/train/000000179392.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000179392.jpg  \n",
            "  inflating: data/images/train/000000361571.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000361571.jpg  \n",
            "  inflating: data/images/train/000000238410.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000238410.jpg  \n",
            "  inflating: data/images/train/000000333237.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000333237.jpg  \n",
            "  inflating: data/images/train/000000311928.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000311928.jpg  \n",
            "  inflating: data/images/train/000000297595.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297595.jpg  \n",
            "  inflating: data/images/train/000000196141.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000196141.jpg  \n",
            "  inflating: data/images/train/000000221155.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000221155.jpg  \n",
            "  inflating: data/images/train/000000472030.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000472030.jpg  \n",
            "  inflating: data/images/train/000000423519.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000423519.jpg  \n",
            "  inflating: data/images/train/000000210388.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000210388.jpg  \n",
            "  inflating: data/images/train/000000540928.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000540928.jpg  \n",
            "  inflating: data/images/train/000000331352.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000331352.jpg  \n",
            "  inflating: data/images/train/000000022396.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000022396.jpg  \n",
            "  inflating: data/images/train/000000147518.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000147518.jpg  \n",
            "  inflating: data/images/train/000000267670.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000267670.jpg  \n",
            "  inflating: data/images/train/000000186422.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186422.jpg  \n",
            "  inflating: data/images/train/000000328601.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000328601.jpg  \n",
            "  inflating: data/images/train/000000445846.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000445846.jpg  \n",
            "  inflating: data/images/train/000000492878.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000492878.jpg  \n",
            "  inflating: data/images/train/000000528314.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000528314.jpg  \n",
            "  inflating: data/images/train/000000360137.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000360137.jpg  \n",
            "  inflating: data/images/train/000000523241.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000523241.jpg  \n",
            "  inflating: data/images/train/000000032811.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000032811.jpg  \n",
            "  inflating: data/images/train/000000369675.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000369675.jpg  \n",
            "  inflating: data/images/train/000000085665.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000085665.jpg  \n",
            "  inflating: data/images/train/000000021879.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000021879.jpg  \n",
            "  inflating: data/images/train/000000269113.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000269113.jpg  \n",
            "  inflating: data/images/train/000000041633.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000041633.jpg  \n",
            "  inflating: data/images/train/000000016958.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000016958.jpg  \n",
            "  inflating: data/images/train/000000431876.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000431876.jpg  \n",
            "  inflating: data/images/train/000000012280.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000012280.jpg  \n",
            "  inflating: data/images/train/000000132622.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000132622.jpg  \n",
            "  inflating: data/images/train/000000453981.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000453981.jpg  \n",
            "  inflating: data/images/train/000000404601.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000404601.jpg  \n",
            "  inflating: data/images/train/000000463842.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000463842.jpg  \n",
            "  inflating: data/images/train/000000395343.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000395343.jpg  \n",
            "  inflating: data/images/train/000000073118.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000073118.jpg  \n",
            "  inflating: data/images/train/000000111951.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000111951.jpg  \n",
            "  inflating: data/images/train/000000452321.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000452321.jpg  \n",
            "  inflating: data/images/train/000000454750.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000454750.jpg  \n",
            "  inflating: data/images/train/000000405279.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000405279.jpg  \n",
            "  inflating: data/images/train/000000484029.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000484029.jpg  \n",
            "  inflating: data/images/train/000000445675.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000445675.jpg  \n",
            "  inflating: data/images/train/000000422836.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000422836.jpg  \n",
            "  inflating: data/images/train/000000501023.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000501023.jpg  \n",
            "  inflating: data/images/train/000000315219.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000315219.jpg  \n",
            "  inflating: data/images/train/000000209142.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000209142.jpg  \n",
            "  inflating: data/images/train/000000206271.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000206271.jpg  \n",
            "  inflating: data/images/train/000000365098.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000365098.jpg  \n",
            "  inflating: data/images/train/000000478286.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000478286.jpg  \n",
            "  inflating: data/images/train/000000350023.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000350023.jpg  \n",
            "  inflating: data/images/train/000000377113.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000377113.jpg  \n",
            "  inflating: data/images/train/000000519491.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000519491.jpg  \n",
            "  inflating: data/images/train/000000154000.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000154000.jpg  \n",
            "  inflating: data/images/train/000000109313.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000109313.jpg  \n",
            "  inflating: data/images/train/000000096427.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000096427.jpg  \n",
            "  inflating: data/images/train/000000166918.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000166918.jpg  \n",
            "  inflating: data/images/train/000000130586.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000130586.jpg  \n",
            "  inflating: data/images/train/000000085329.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000085329.jpg  \n",
            "  inflating: data/images/train/000000267300.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000267300.jpg  \n",
            "  inflating: data/images/train/000000152465.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000152465.jpg  \n",
            "  inflating: data/images/train/000000333745.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000333745.jpg  \n",
            "  inflating: data/images/train/000000005529.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000005529.jpg  \n",
            "  inflating: data/images/train/000000533536.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000533536.jpg  \n",
            "  inflating: data/images/train/000000185473.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000185473.jpg  \n",
            "  inflating: data/images/train/000000575205.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000575205.jpg  \n",
            "  inflating: data/images/train/000000481390.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000481390.jpg  \n",
            "  inflating: data/images/train/000000036861.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000036861.jpg  \n",
            "  inflating: data/images/train/000000319184.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000319184.jpg  \n",
            "  inflating: data/images/train/000000091406.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000091406.jpg  \n",
            "  inflating: data/images/train/000000478721.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000478721.jpg  \n",
            "  inflating: data/images/train/000000170613.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000170613.jpg  \n",
            "  inflating: data/images/train/000000482100.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000482100.jpg  \n",
            "  inflating: data/images/train/000000287545.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000287545.jpg  \n",
            "  inflating: data/images/train/000000395633.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000395633.jpg  \n",
            "  inflating: data/images/train/000000248334.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000248334.jpg  \n",
            "  inflating: data/images/train/000000069356.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000069356.jpg  \n",
            "  inflating: data/images/train/000000344268.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000344268.jpg  \n",
            "  inflating: data/images/train/000000493019.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000493019.jpg  \n",
            "  inflating: data/images/train/000000127987.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000127987.jpg  \n",
            "  inflating: data/images/train/000000169356.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000169356.jpg  \n",
            "  inflating: data/images/train/000000257566.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000257566.jpg  \n",
            "  inflating: data/images/train/000000442456.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000442456.jpg  \n",
            "  inflating: data/images/train/000000167353.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000167353.jpg  \n",
            "  inflating: data/images/train/000000414638.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000414638.jpg  \n",
            "  inflating: data/images/train/000000518770.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000518770.jpg  \n",
            "  inflating: data/images/train/000000240754.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000240754.jpg  \n",
            "  inflating: data/images/train/000000416991.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000416991.jpg  \n",
            "  inflating: data/images/train/000000161044.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000161044.jpg  \n",
            "  inflating: data/images/train/000000407650.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000407650.jpg  \n",
            "  inflating: data/images/train/000000130579.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000130579.jpg  \n",
            "  inflating: data/images/train/000000073326.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000073326.jpg  \n",
            "  inflating: data/images/train/000000132408.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000132408.jpg  \n",
            "  inflating: data/images/train/000000411754.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000411754.jpg  \n",
            "  inflating: data/images/train/000000092053.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000092053.jpg  \n",
            "  inflating: data/images/train/000000271402.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000271402.jpg  \n",
            "  inflating: data/images/train/000000455937.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000455937.jpg  \n",
            "  inflating: data/images/train/000000349837.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000349837.jpg  \n",
            "  inflating: data/images/train/000000192047.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000192047.jpg  \n",
            "  inflating: data/images/train/000000042070.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000042070.jpg  \n",
            "  inflating: data/images/train/000000391290.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000391290.jpg  \n",
            "  inflating: data/images/train/000000281929.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000281929.jpg  \n",
            "  inflating: data/images/train/000000481582.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000481582.jpg  \n",
            "  inflating: data/images/train/000000475365.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000475365.jpg  \n",
            "  inflating: data/images/train/000000423123.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000423123.jpg  \n",
            "  inflating: data/images/train/000000400922.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000400922.jpg  \n",
            "  inflating: data/images/train/000000136915.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000136915.jpg  \n",
            "  inflating: data/images/train/000000286908.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000286908.jpg  \n",
            "  inflating: data/images/train/000000369503.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000369503.jpg  \n",
            "  inflating: data/images/train/000000507081.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000507081.jpg  \n",
            "  inflating: data/images/train/000000496954.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000496954.jpg  \n",
            "  inflating: data/images/train/000000552902.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000552902.jpg  \n",
            "  inflating: data/images/train/000000087476.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000087476.jpg  \n",
            "  inflating: data/images/train/000000301867.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000301867.jpg  \n",
            "  inflating: data/images/train/000000521052.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000521052.jpg  \n",
            "  inflating: data/images/train/000000509735.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000509735.jpg  \n",
            "  inflating: data/images/train/000000490470.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000490470.jpg  \n",
            "  inflating: data/images/train/000000245764.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000245764.jpg  \n",
            "  inflating: data/images/train/000000491008.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000491008.jpg  \n",
            "  inflating: data/images/train/000000079031.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000079031.jpg  \n",
            "  inflating: data/images/train/000000516173.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000516173.jpg  \n",
            "  inflating: data/images/train/000000516601.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000516601.jpg  \n",
            "  inflating: data/images/train/000000343315.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000343315.jpg  \n",
            "  inflating: data/images/train/000000033104.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000033104.jpg  \n",
            "  inflating: data/images/train/000000212166.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000212166.jpg  \n",
            "  inflating: data/images/train/000000140840.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000140840.jpg  \n",
            "  inflating: data/images/train/000000507042.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000507042.jpg  \n",
            "  inflating: data/images/train/000000071451.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000071451.jpg  \n",
            "  inflating: data/images/train/000000530836.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000530836.jpg  \n",
            "  inflating: data/images/train/000000135561.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000135561.jpg  \n",
            "  inflating: data/images/train/000000447314.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000447314.jpg  \n",
            "  inflating: data/images/train/000000460967.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000460967.jpg  \n",
            "  inflating: data/images/train/000000517523.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000517523.jpg  \n",
            "  inflating: data/images/train/000000161642.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000161642.jpg  \n",
            "  inflating: data/images/train/000000572620.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000572620.jpg  \n",
            "  inflating: data/images/train/000000329319.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000329319.jpg  \n",
            "  inflating: data/images/train/000000199310.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000199310.jpg  \n",
            "  inflating: data/images/train/000000040471.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000040471.jpg  \n",
            "  inflating: data/images/train/000000030828.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000030828.jpg  \n",
            "  inflating: data/images/train/000000103548.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000103548.jpg  \n",
            "  inflating: data/images/train/000000573258.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000573258.jpg  \n",
            "  inflating: data/images/train/000000062808.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000062808.jpg  \n",
            "  inflating: data/images/train/000000470779.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000470779.jpg  \n",
            "  inflating: data/images/train/000000153343.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000153343.jpg  \n",
            "  inflating: data/images/train/000000270244.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000270244.jpg  \n",
            "  inflating: data/images/train/000000364557.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000364557.jpg  \n",
            "  inflating: data/images/train/000000042528.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000042528.jpg  \n",
            "  inflating: data/images/train/000000436738.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000436738.jpg  \n",
            "  inflating: data/images/train/000000538067.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000538067.jpg  \n",
            "  inflating: data/images/train/000000094185.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000094185.jpg  \n",
            "  inflating: data/images/train/000000476491.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000476491.jpg  \n",
            "  inflating: data/images/train/000000449661.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000449661.jpg  \n",
            "  inflating: data/images/train/000000232088.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000232088.jpg  \n",
            "  inflating: data/images/train/000000269932.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000269932.jpg  \n",
            "  inflating: data/images/train/000000335081.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000335081.jpg  \n",
            "  inflating: data/images/train/000000308466.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000308466.jpg  \n",
            "  inflating: data/images/train/000000120420.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000120420.jpg  \n",
            "  inflating: data/images/train/000000168458.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000168458.jpg  \n",
            "  inflating: data/images/train/000000554156.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000554156.jpg  \n",
            "  inflating: data/images/train/000000227491.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000227491.jpg  \n",
            "  inflating: data/images/train/000000250619.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000250619.jpg  \n",
            "  inflating: data/images/train/000000496571.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000496571.jpg  \n",
            "  inflating: data/images/train/000000308328.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000308328.jpg  \n",
            "  inflating: data/images/train/000000255749.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000255749.jpg  \n",
            "  inflating: data/images/train/000000344888.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000344888.jpg  \n",
            "  inflating: data/images/train/000000163257.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000163257.jpg  \n",
            "  inflating: data/images/train/000000173044.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000173044.jpg  \n",
            "  inflating: data/images/train/000000386277.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000386277.jpg  \n",
            "  inflating: data/images/train/000000061333.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000061333.jpg  \n",
            "  inflating: data/images/train/000000503755.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000503755.jpg  \n",
            "  inflating: data/images/train/000000074058.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000074058.jpg  \n",
            "  inflating: data/images/train/000000479953.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000479953.jpg  \n",
            "  inflating: data/images/train/000000023666.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000023666.jpg  \n",
            "  inflating: data/images/train/000000412894.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000412894.jpg  \n",
            "  inflating: data/images/train/000000413552.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000413552.jpg  \n",
            "  inflating: data/images/train/000000362682.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000362682.jpg  \n",
            "  inflating: data/images/train/000000520832.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000520832.jpg  \n",
            "  inflating: data/images/train/000000050844.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000050844.jpg  \n",
            "  inflating: data/images/train/000000310200.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000310200.jpg  \n",
            "  inflating: data/images/train/000000262682.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000262682.jpg  \n",
            "  inflating: data/images/train/000000297353.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297353.jpg  \n",
            "  inflating: data/images/train/000000347370.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000347370.jpg  \n",
            "  inflating: data/images/train/000000459467.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000459467.jpg  \n",
            "  inflating: data/images/train/000000474293.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000474293.jpg  \n",
            "  inflating: data/images/train/000000159684.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000159684.jpg  \n",
            "  inflating: data/images/train/000000406611.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000406611.jpg  \n",
            "  inflating: data/images/train/000000085089.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000085089.jpg  \n",
            "  inflating: data/images/train/000000549674.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000549674.jpg  \n",
            "  inflating: data/images/train/000000391722.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000391722.jpg  \n",
            "  inflating: data/images/train/000000231580.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000231580.jpg  \n",
            "  inflating: data/images/train/000000234413.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000234413.jpg  \n",
            "  inflating: data/images/train/000000329456.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000329456.jpg  \n",
            "  inflating: data/images/train/000000324614.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000324614.jpg  \n",
            "  inflating: data/images/train/000000268378.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000268378.jpg  \n",
            "  inflating: data/images/train/000000537355.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000537355.jpg  \n",
            "  inflating: data/images/train/000000581781.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000581781.jpg  \n",
            "  inflating: data/images/train/000000089880.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000089880.jpg  \n",
            "  inflating: data/images/train/000000157124.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000157124.jpg  \n",
            "  inflating: data/images/train/000000417085.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000417085.jpg  \n",
            "  inflating: data/images/train/000000389804.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000389804.jpg  \n",
            "  inflating: data/images/train/000000235057.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000235057.jpg  \n",
            "  inflating: data/images/train/000000359833.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000359833.jpg  \n",
            "  inflating: data/images/train/000000089670.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000089670.jpg  \n",
            "  inflating: data/images/train/000000294855.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000294855.jpg  \n",
            "  inflating: data/images/train/000000246522.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000246522.jpg  \n",
            "  inflating: data/images/train/000000066886.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000066886.jpg  \n",
            "  inflating: data/images/train/000000018380.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000018380.jpg  \n",
            "  inflating: data/images/train/000000314264.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000314264.jpg  \n",
            "  inflating: data/images/train/000000555705.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000555705.jpg  \n",
            "  inflating: data/images/train/000000167540.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000167540.jpg  \n",
            "  inflating: data/images/train/000000508370.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000508370.jpg  \n",
            "  inflating: data/images/train/000000168883.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000168883.jpg  \n",
            "  inflating: data/images/train/000000465822.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000465822.jpg  \n",
            "  inflating: data/images/train/000000557884.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000557884.jpg  \n",
            "  inflating: data/images/train/000000010092.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000010092.jpg  \n",
            "  inflating: data/images/train/000000292997.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000292997.jpg  \n",
            "  inflating: data/images/train/000000484404.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000484404.jpg  \n",
            "  inflating: data/images/train/000000004795.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000004795.jpg  \n",
            "  inflating: data/images/train/000000457884.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000457884.jpg  \n",
            "  inflating: data/images/train/000000092091.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000092091.jpg  \n",
            "  inflating: data/images/train/000000501368.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000501368.jpg  \n",
            "  inflating: data/images/train/000000537802.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000537802.jpg  \n",
            "  inflating: data/images/train/000000571857.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000571857.jpg  \n",
            "  inflating: data/images/train/000000227686.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000227686.jpg  \n",
            "  inflating: data/images/train/000000465836.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000465836.jpg  \n",
            "  inflating: data/images/train/000000343466.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000343466.jpg  \n",
            "  inflating: data/images/train/000000172617.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000172617.jpg  \n",
            "  inflating: data/images/train/000000310980.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000310980.jpg  \n",
            "  inflating: data/images/train/000000252219.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000252219.jpg  \n",
            "  inflating: data/images/train/000000007511.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000007511.jpg  \n",
            "  inflating: data/images/train/000000546976.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000546976.jpg  \n",
            "  inflating: data/images/train/000000153632.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000153632.jpg  \n",
            "  inflating: data/images/train/000000425221.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000425221.jpg  \n",
            "  inflating: data/images/train/000000170955.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000170955.jpg  \n",
            "  inflating: data/images/train/000000043435.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000043435.jpg  \n",
            "  inflating: data/images/train/000000053626.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000053626.jpg  \n",
            "  inflating: data/images/train/000000356094.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000356094.jpg  \n",
            "  inflating: data/images/train/000000526728.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000526728.jpg  \n",
            "  inflating: data/images/train/000000528705.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000528705.jpg  \n",
            "  inflating: data/images/train/000000047121.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000047121.jpg  \n",
            "  inflating: data/images/train/000000559842.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000559842.jpg  \n",
            "  inflating: data/images/train/000000272136.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000272136.jpg  \n",
            "  inflating: data/images/train/000000328238.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000328238.jpg  \n",
            "  inflating: data/images/train/000000320664.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000320664.jpg  \n",
            "  inflating: data/images/train/000000504589.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000504589.jpg  \n",
            "  inflating: data/images/train/000000058029.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000058029.jpg  \n",
            "  inflating: data/images/train/000000086755.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000086755.jpg  \n",
            "  inflating: data/images/train/000000012120.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000012120.jpg  \n",
            "  inflating: data/images/train/000000530162.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000530162.jpg  \n",
            "  inflating: data/images/train/000000256916.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000256916.jpg  \n",
            "  inflating: data/images/train/000000197658.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000197658.jpg  \n",
            "  inflating: data/images/train/000000532761.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000532761.jpg  \n",
            "  inflating: data/images/train/000000203095.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000203095.jpg  \n",
            "  inflating: data/images/train/000000384850.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000384850.jpg  \n",
            "  inflating: data/images/train/000000235241.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000235241.jpg  \n",
            "  inflating: data/images/train/000000511999.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000511999.jpg  \n",
            "  inflating: data/images/train/000000512248.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000512248.jpg  \n",
            "  inflating: data/images/train/000000306700.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000306700.jpg  \n",
            "  inflating: data/images/train/000000380203.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000380203.jpg  \n",
            "  inflating: data/images/train/000000164883.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000164883.jpg  \n",
            "  inflating: data/images/train/000000098392.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000098392.jpg  \n",
            "  inflating: data/images/train/000000394510.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000394510.jpg  \n",
            "  inflating: data/images/train/000000078266.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000078266.jpg  \n",
            "  inflating: data/images/train/000000014380.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000014380.jpg  \n",
            "  inflating: data/images/train/000000024243.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000024243.jpg  \n",
            "  inflating: data/images/train/000000134722.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000134722.jpg  \n",
            "  inflating: data/images/train/000000452122.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000452122.jpg  \n",
            "  inflating: data/images/train/000000164115.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000164115.jpg  \n",
            "  inflating: data/images/train/000000202228.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000202228.jpg  \n",
            "  inflating: data/images/train/000000038118.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000038118.jpg  \n",
            "  inflating: data/images/train/000000079144.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000079144.jpg  \n",
            "  inflating: data/images/train/000000357567.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000357567.jpg  \n",
            "  inflating: data/images/train/000000379842.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000379842.jpg  \n",
            "  inflating: data/images/train/000000409867.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000409867.jpg  \n",
            "  inflating: data/images/train/000000395801.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000395801.jpg  \n",
            "  inflating: data/images/train/000000187271.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000187271.jpg  \n",
            "  inflating: data/images/train/000000009448.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000009448.jpg  \n",
            "  inflating: data/images/train/000000155451.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000155451.jpg  \n",
            "  inflating: data/images/train/000000303863.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000303863.jpg  \n",
            "  inflating: data/images/train/000000438304.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000438304.jpg  \n",
            "  inflating: data/images/train/000000111207.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000111207.jpg  \n",
            "  inflating: data/images/train/000000369310.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000369310.jpg  \n",
            "  inflating: data/images/train/000000236166.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000236166.jpg  \n",
            "  inflating: data/images/train/000000001000.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000001000.jpg  \n",
            "  inflating: data/images/train/000000185472.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000185472.jpg  \n",
            "  inflating: data/images/train/000000513181.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000513181.jpg  \n",
            "  inflating: data/images/train/000000550084.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000550084.jpg  \n",
            "  inflating: data/images/train/000000372718.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000372718.jpg  \n",
            "  inflating: data/images/train/000000374369.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000374369.jpg  \n",
            "  inflating: data/images/train/000000535608.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000535608.jpg  \n",
            "  inflating: data/images/train/000000436315.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000436315.jpg  \n",
            "  inflating: data/images/train/000000534270.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000534270.jpg  \n",
            "  inflating: data/images/train/000000442480.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000442480.jpg  \n",
            "  inflating: data/images/train/000000460147.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000460147.jpg  \n",
            "  inflating: data/images/train/000000146363.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000146363.jpg  \n",
            "  inflating: data/images/train/000000336628.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000336628.jpg  \n",
            "  inflating: data/images/train/000000064868.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000064868.jpg  \n",
            "  inflating: data/images/train/000000079408.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000079408.jpg  \n",
            "  inflating: data/images/train/000000177357.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000177357.jpg  \n",
            "  inflating: data/images/train/000000150930.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000150930.jpg  \n",
            "  inflating: data/images/train/000000169169.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000169169.jpg  \n",
            "  inflating: data/images/train/000000125405.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125405.jpg  \n",
            "  inflating: data/images/train/000000408774.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000408774.jpg  \n",
            "  inflating: data/images/train/000000431693.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000431693.jpg  \n",
            "  inflating: data/images/train/000000455301.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000455301.jpg  \n",
            "  inflating: data/images/train/000000317433.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000317433.jpg  \n",
            "  inflating: data/images/train/000000542127.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000542127.jpg  \n",
            "  inflating: data/images/train/000000216739.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000216739.jpg  \n",
            "  inflating: data/images/train/000000466085.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000466085.jpg  \n",
            "  inflating: data/images/train/000000286458.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000286458.jpg  \n",
            "  inflating: data/images/train/000000204329.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000204329.jpg  \n",
            "  inflating: data/images/train/000000345361.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000345361.jpg  \n",
            "  inflating: data/images/train/000000211042.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000211042.jpg  \n",
            "  inflating: data/images/train/000000283520.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000283520.jpg  \n",
            "  inflating: data/images/train/000000559513.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000559513.jpg  \n",
            "  inflating: data/images/train/000000343076.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000343076.jpg  \n",
            "  inflating: data/images/train/000000557258.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000557258.jpg  \n",
            "  inflating: data/images/train/000000492110.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000492110.jpg  \n",
            "  inflating: data/images/train/000000371749.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000371749.jpg  \n",
            "  inflating: data/images/train/000000039951.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000039951.jpg  \n",
            "  inflating: data/images/train/000000088432.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000088432.jpg  \n",
            "  inflating: data/images/train/000000343937.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000343937.jpg  \n",
            "  inflating: data/images/train/000000342397.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000342397.jpg  \n",
            "  inflating: data/images/train/000000522638.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000522638.jpg  \n",
            "  inflating: data/images/train/000000460379.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000460379.jpg  \n",
            "  inflating: data/images/train/000000311081.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000311081.jpg  \n",
            "  inflating: data/images/train/000000263403.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000263403.jpg  \n",
            "  inflating: data/images/train/000000447088.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000447088.jpg  \n",
            "  inflating: data/images/train/000000186345.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186345.jpg  \n",
            "  inflating: data/images/train/000000156372.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000156372.jpg  \n",
            "  inflating: data/images/train/000000030785.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000030785.jpg  \n",
            "  inflating: data/images/train/000000366225.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000366225.jpg  \n",
            "  inflating: data/images/train/000000091615.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000091615.jpg  \n",
            "  inflating: data/images/train/000000291861.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000291861.jpg  \n",
            "  inflating: data/images/train/000000517687.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000517687.jpg  \n",
            "  inflating: data/images/train/000000571264.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000571264.jpg  \n",
            "  inflating: data/images/train/000000005060.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000005060.jpg  \n",
            "  inflating: data/images/train/000000361238.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000361238.jpg  \n",
            "  inflating: data/images/train/000000236412.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000236412.jpg  \n",
            "  inflating: data/images/train/000000527750.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000527750.jpg  \n",
            "  inflating: data/images/train/000000565563.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000565563.jpg  \n",
            "  inflating: data/images/train/000000566042.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000566042.jpg  \n",
            "  inflating: data/images/train/000000094751.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000094751.jpg  \n",
            "  inflating: data/images/train/000000564133.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000564133.jpg  \n",
            "  inflating: data/images/train/000000185890.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000185890.jpg  \n",
            "  inflating: data/images/train/000000287959.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000287959.jpg  \n",
            "  inflating: data/images/train/000000153568.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000153568.jpg  \n",
            "  inflating: data/images/train/000000474452.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000474452.jpg  \n",
            "  inflating: data/images/train/000000154213.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000154213.jpg  \n",
            "  inflating: data/images/train/000000104424.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000104424.jpg  \n",
            "  inflating: data/images/train/000000289960.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000289960.jpg  \n",
            "  inflating: data/images/train/000000564127.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000564127.jpg  \n",
            "  inflating: data/images/train/000000563648.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000563648.jpg  \n",
            "  inflating: data/images/train/000000137950.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000137950.jpg  \n",
            "  inflating: data/images/train/000000551822.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000551822.jpg  \n",
            "  inflating: data/images/train/000000323751.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000323751.jpg  \n",
            "  inflating: data/images/train/000000212573.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000212573.jpg  \n",
            "  inflating: data/images/train/000000171050.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000171050.jpg  \n",
            "  inflating: data/images/train/000000549738.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000549738.jpg  \n",
            "  inflating: data/images/train/000000037777.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000037777.jpg  \n",
            "  inflating: data/images/train/000000292415.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000292415.jpg  \n",
            "  inflating: data/images/train/000000464872.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000464872.jpg  \n",
            "  inflating: data/images/train/000000121673.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000121673.jpg  \n",
            "  inflating: data/images/train/000000302760.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000302760.jpg  \n",
            "  inflating: data/images/train/000000529966.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000529966.jpg  \n",
            "  inflating: data/images/train/000000302990.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000302990.jpg  \n",
            "  inflating: data/images/train/000000355610.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000355610.jpg  \n",
            "  inflating: data/images/train/000000295420.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000295420.jpg  \n",
            "  inflating: data/images/train/000000082696.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000082696.jpg  \n",
            "  inflating: data/images/train/000000562581.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000562581.jpg  \n",
            "  inflating: data/images/train/000000004395.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000004395.jpg  \n",
            "  inflating: data/images/train/000000553990.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000553990.jpg  \n",
            "  inflating: data/images/train/000000196185.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000196185.jpg  \n",
            "  inflating: data/images/train/000000445658.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000445658.jpg  \n",
            "  inflating: data/images/train/000000172571.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000172571.jpg  \n",
            "  inflating: data/images/train/000000224200.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000224200.jpg  \n",
            "  inflating: data/images/train/000000467176.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000467176.jpg  \n",
            "  inflating: data/images/train/000000468245.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000468245.jpg  \n",
            "  inflating: data/images/train/000000527220.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000527220.jpg  \n",
            "  inflating: data/images/train/000000226417.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000226417.jpg  \n",
            "  inflating: data/images/train/000000239537.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000239537.jpg  \n",
            "  inflating: data/images/train/000000475572.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000475572.jpg  \n",
            "  inflating: data/images/train/000000392818.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000392818.jpg  \n",
            "  inflating: data/images/train/000000461275.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000461275.jpg  \n",
            "  inflating: data/images/train/000000535156.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000535156.jpg  \n",
            "  inflating: data/images/train/000000187513.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000187513.jpg  \n",
            "  inflating: data/images/train/000000386879.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000386879.jpg  \n",
            "  inflating: data/images/train/000000269314.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000269314.jpg  \n",
            "  inflating: data/images/train/000000101762.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000101762.jpg  \n",
            "  inflating: data/images/train/000000289586.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000289586.jpg  \n",
            "  inflating: data/images/train/000000377670.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000377670.jpg  \n",
            "  inflating: data/images/train/000000127955.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000127955.jpg  \n",
            "  inflating: data/images/train/000000322895.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000322895.jpg  \n",
            "  inflating: data/images/train/000000106757.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000106757.jpg  \n",
            "  inflating: data/images/train/000000119677.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000119677.jpg  \n",
            "  inflating: data/images/train/000000187249.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000187249.jpg  \n",
            "  inflating: data/images/train/000000135410.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000135410.jpg  \n",
            "  inflating: data/images/train/000000485130.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000485130.jpg  \n",
            "  inflating: data/images/train/000000296317.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000296317.jpg  \n",
            "  inflating: data/images/train/000000215778.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000215778.jpg  \n",
            "  inflating: data/images/train/000000510329.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000510329.jpg  \n",
            "  inflating: data/images/train/000000070158.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000070158.jpg  \n",
            "  inflating: data/images/train/000000363188.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000363188.jpg  \n",
            "  inflating: data/images/train/000000240023.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000240023.jpg  \n",
            "  inflating: data/images/train/000000021465.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000021465.jpg  \n",
            "  inflating: data/images/train/000000025603.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000025603.jpg  \n",
            "  inflating: data/images/train/000000023272.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000023272.jpg  \n",
            "  inflating: data/images/train/000000033707.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000033707.jpg  \n",
            "  inflating: data/images/train/000000416758.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000416758.jpg  \n",
            "  inflating: data/images/train/000000531495.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000531495.jpg  \n",
            "  inflating: data/images/train/000000195842.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000195842.jpg  \n",
            "  inflating: data/images/train/000000027982.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000027982.jpg  \n",
            "  inflating: data/images/train/000000066706.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000066706.jpg  \n",
            "  inflating: data/images/train/000000245173.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000245173.jpg  \n",
            "  inflating: data/images/train/000000131138.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000131138.jpg  \n",
            "  inflating: data/images/train/000000490515.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000490515.jpg  \n",
            "  inflating: data/images/train/000000060363.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060363.jpg  \n",
            "  inflating: data/images/train/000000163118.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000163118.jpg  \n",
            "  inflating: data/images/train/000000246308.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000246308.jpg  \n",
            "  inflating: data/images/train/000000232489.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000232489.jpg  \n",
            "  inflating: data/images/train/000000048564.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000048564.jpg  \n",
            "  inflating: data/images/train/000000066841.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000066841.jpg  \n",
            "  inflating: data/images/train/000000352584.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000352584.jpg  \n",
            "  inflating: data/images/train/000000537153.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000537153.jpg  \n",
            "  inflating: data/images/train/000000403584.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000403584.jpg  \n",
            "  inflating: data/images/train/000000416837.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000416837.jpg  \n",
            "  inflating: data/images/train/000000478136.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000478136.jpg  \n",
            "  inflating: data/images/train/000000323355.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000323355.jpg  \n",
            "  inflating: data/images/train/000000521719.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000521719.jpg  \n",
            "  inflating: data/images/train/000000274219.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000274219.jpg  \n",
            "  inflating: data/images/train/000000284698.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000284698.jpg  \n",
            "  inflating: data/images/train/000000464251.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000464251.jpg  \n",
            "  inflating: data/images/train/000000228214.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000228214.jpg  \n",
            "  inflating: data/images/train/000000238013.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000238013.jpg  \n",
            "  inflating: data/images/train/000000033854.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000033854.jpg  \n",
            "  inflating: data/images/train/000000193348.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000193348.jpg  \n",
            "  inflating: data/images/train/000000450686.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000450686.jpg  \n",
            "  inflating: data/images/train/000000207585.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000207585.jpg  \n",
            "  inflating: data/images/train/000000189310.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000189310.jpg  \n",
            "  inflating: data/images/train/000000019924.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000019924.jpg  \n",
            "  inflating: data/images/train/000000393469.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000393469.jpg  \n",
            "  inflating: data/images/train/000000289343.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000289343.jpg  \n",
            "  inflating: data/images/train/000000292005.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000292005.jpg  \n",
            "  inflating: data/images/train/000000491757.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000491757.jpg  \n",
            "  inflating: data/images/train/000000141597.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000141597.jpg  \n",
            "  inflating: data/images/train/000000551215.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000551215.jpg  \n",
            "  inflating: data/images/train/000000406417.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000406417.jpg  \n",
            "  inflating: data/images/train/000000079034.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000079034.jpg  \n",
            "  inflating: data/images/train/000000444142.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000444142.jpg  \n",
            "  inflating: data/images/train/000000162366.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000162366.jpg  \n",
            "  inflating: data/images/train/000000512476.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000512476.jpg  \n",
            "  inflating: data/images/train/000000317999.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000317999.jpg  \n",
            "  inflating: data/images/train/000000213255.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213255.jpg  \n",
            "  inflating: data/images/train/000000474095.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000474095.jpg  \n",
            "  inflating: data/images/train/000000537812.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000537812.jpg  \n",
            "  inflating: data/images/train/000000445248.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000445248.jpg  \n",
            "  inflating: data/images/train/000000000285.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000000285.jpg  \n",
            "  inflating: data/images/train/000000437351.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000437351.jpg  \n",
            "  inflating: data/images/train/000000334371.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000334371.jpg  \n",
            "  inflating: data/images/train/000000191013.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000191013.jpg  \n",
            "  inflating: data/images/train/000000155051.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000155051.jpg  \n",
            "  inflating: data/images/train/000000220310.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000220310.jpg  \n",
            "  inflating: data/images/train/000000334417.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000334417.jpg  \n",
            "  inflating: data/images/train/000000193162.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000193162.jpg  \n",
            "  inflating: data/images/train/000000089648.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000089648.jpg  \n",
            "  inflating: data/images/train/000000191761.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000191761.jpg  \n",
            "  inflating: data/images/train/000000013004.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000013004.jpg  \n",
            "  inflating: data/images/train/000000221754.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000221754.jpg  \n",
            "  inflating: data/images/train/000000225532.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000225532.jpg  \n",
            "  inflating: data/images/train/000000439426.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000439426.jpg  \n",
            "  inflating: data/images/train/000000293858.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000293858.jpg  \n",
            "  inflating: data/images/train/000000209972.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000209972.jpg  \n",
            "  inflating: data/images/train/000000536073.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000536073.jpg  \n",
            "  inflating: data/images/train/000000011149.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000011149.jpg  \n",
            "  inflating: data/images/train/000000435208.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000435208.jpg  \n",
            "  inflating: data/images/train/000000094157.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000094157.jpg  \n",
            "  inflating: data/images/train/000000534664.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000534664.jpg  \n",
            "  inflating: data/images/train/000000273760.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000273760.jpg  \n",
            "  inflating: data/images/train/000000088218.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000088218.jpg  \n",
            "  inflating: data/images/train/000000196754.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000196754.jpg  \n",
            "  inflating: data/images/train/000000546219.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000546219.jpg  \n",
            "  inflating: data/images/train/000000499109.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000499109.jpg  \n",
            "  inflating: data/images/train/000000217219.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000217219.jpg  \n",
            "  inflating: data/images/train/000000521282.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000521282.jpg  \n",
            "  inflating: data/images/train/000000458755.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000458755.jpg  \n",
            "  inflating: data/images/train/000000512648.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000512648.jpg  \n",
            "  inflating: data/images/train/000000437392.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000437392.jpg  \n",
            "  inflating: data/images/train/000000128051.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000128051.jpg  \n",
            "  inflating: data/images/train/000000453166.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000453166.jpg  \n",
            "  inflating: data/images/train/000000305609.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000305609.jpg  \n",
            "  inflating: data/images/train/000000517056.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000517056.jpg  \n",
            "  inflating: data/images/train/000000409268.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000409268.jpg  \n",
            "  inflating: data/images/train/000000297343.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297343.jpg  \n",
            "  inflating: data/images/train/000000500270.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500270.jpg  \n",
            "  inflating: data/images/train/000000134322.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000134322.jpg  \n",
            "  inflating: data/images/train/000000402473.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000402473.jpg  \n",
            "  inflating: data/images/train/000000574297.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000574297.jpg  \n",
            "  inflating: data/images/train/000000236599.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000236599.jpg  \n",
            "  inflating: data/images/train/000000546556.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000546556.jpg  \n",
            "  inflating: data/images/train/000000564091.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000564091.jpg  \n",
            "  inflating: data/images/train/000000245576.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000245576.jpg  \n",
            "  inflating: data/images/train/000000383337.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000383337.jpg  \n",
            "  inflating: data/images/train/000000570782.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000570782.jpg  \n",
            "  inflating: data/images/train/000000508639.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000508639.jpg  \n",
            "  inflating: data/images/train/000000082085.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000082085.jpg  \n",
            "  inflating: data/images/train/000000308476.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000308476.jpg  \n",
            "  inflating: data/images/train/000000458768.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000458768.jpg  \n",
            "  inflating: data/images/train/000000160772.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000160772.jpg  \n",
            "  inflating: data/images/train/000000002685.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000002685.jpg  \n",
            "  inflating: data/images/train/000000394677.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000394677.jpg  \n",
            "  inflating: data/images/train/000000228942.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000228942.jpg  \n",
            "  inflating: data/images/train/000000267933.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000267933.jpg  \n",
            "  inflating: data/images/train/000000018193.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000018193.jpg  \n",
            "  inflating: data/images/train/000000312406.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000312406.jpg  \n",
            "  inflating: data/images/train/000000270297.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000270297.jpg  \n",
            "  inflating: data/images/train/000000131273.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000131273.jpg  \n",
            "  inflating: data/images/train/000000495732.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000495732.jpg  \n",
            "  inflating: data/images/train/000000417043.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000417043.jpg  \n",
            "  inflating: data/images/train/000000025560.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000025560.jpg  \n",
            "  inflating: data/images/train/000000348708.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000348708.jpg  \n",
            "  inflating: data/images/train/000000495054.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000495054.jpg  \n",
            "  inflating: data/images/train/000000042276.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000042276.jpg  \n",
            "  inflating: data/images/train/000000522007.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000522007.jpg  \n",
            "  inflating: data/images/train/000000069795.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000069795.jpg  \n",
            "  inflating: data/images/train/000000086220.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000086220.jpg  \n",
            "  inflating: data/images/train/000000228771.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000228771.jpg  \n",
            "  inflating: data/images/train/000000226984.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000226984.jpg  \n",
            "  inflating: data/images/train/000000325527.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000325527.jpg  \n",
            "  inflating: data/images/train/000000100723.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000100723.jpg  \n",
            "  inflating: data/images/train/000000158548.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000158548.jpg  \n",
            "  inflating: data/images/train/000000228981.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000228981.jpg  \n",
            "  inflating: data/images/train/000000050896.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000050896.jpg  \n",
            "  inflating: data/images/train/000000513580.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000513580.jpg  \n",
            "  inflating: data/images/train/000000018150.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000018150.jpg  \n",
            "  inflating: data/images/train/000000163290.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000163290.jpg  \n",
            "  inflating: data/images/train/000000329447.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000329447.jpg  \n",
            "  inflating: data/images/train/000000376625.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000376625.jpg  \n",
            "  inflating: data/images/train/000000389197.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000389197.jpg  \n",
            "  inflating: data/images/train/000000061108.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000061108.jpg  \n",
            "  inflating: data/images/train/000000132544.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000132544.jpg  \n",
            "  inflating: data/images/train/000000484415.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000484415.jpg  \n",
            "  inflating: data/images/train/000000287347.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000287347.jpg  \n",
            "  inflating: data/images/train/000000158945.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000158945.jpg  \n",
            "  inflating: data/images/train/000000039405.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000039405.jpg  \n",
            "  inflating: data/images/train/000000257370.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000257370.jpg  \n",
            "  inflating: data/images/train/000000162415.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000162415.jpg  \n",
            "  inflating: data/images/train/000000051961.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000051961.jpg  \n",
            "  inflating: data/images/train/000000439180.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000439180.jpg  \n",
            "  inflating: data/images/train/000000478862.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000478862.jpg  \n",
            "  inflating: data/images/train/000000347163.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000347163.jpg  \n",
            "  inflating: data/images/train/000000025986.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000025986.jpg  \n",
            "  inflating: data/images/train/000000279927.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000279927.jpg  \n",
            "  inflating: data/images/train/000000519522.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000519522.jpg  \n",
            "  inflating: data/images/train/000000117908.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000117908.jpg  \n",
            "  inflating: data/images/train/000000033114.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000033114.jpg  \n",
            "  inflating: data/images/train/000000001818.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000001818.jpg  \n",
            "  inflating: data/images/train/000000509719.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000509719.jpg  \n",
            "  inflating: data/images/train/000000384666.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000384666.jpg  \n",
            "  inflating: data/images/train/000000155291.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000155291.jpg  \n",
            "  inflating: data/images/train/000000161861.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000161861.jpg  \n",
            "  inflating: data/images/train/000000132587.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000132587.jpg  \n",
            "  inflating: data/images/train/000000051008.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000051008.jpg  \n",
            "  inflating: data/images/train/000000576654.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000576654.jpg  \n",
            "  inflating: data/images/train/000000539143.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000539143.jpg  \n",
            "  inflating: data/images/train/000000464522.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000464522.jpg  \n",
            "  inflating: data/images/train/000000321557.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000321557.jpg  \n",
            "  inflating: data/images/train/000000014226.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000014226.jpg  \n",
            "  inflating: data/images/train/000000452084.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000452084.jpg  \n",
            "  inflating: data/images/train/000000227898.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000227898.jpg  \n",
            "  inflating: data/images/train/000000541952.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000541952.jpg  \n",
            "  inflating: data/images/train/000000239318.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000239318.jpg  \n",
            "  inflating: data/images/train/000000411817.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000411817.jpg  \n",
            "  inflating: data/images/train/000000161875.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000161875.jpg  \n",
            "  inflating: data/images/train/000000054164.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000054164.jpg  \n",
            "  inflating: data/images/train/000000279714.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000279714.jpg  \n",
            "  inflating: data/images/train/000000083172.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000083172.jpg  \n",
            "  inflating: data/images/train/000000527427.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000527427.jpg  \n",
            "  inflating: data/images/train/000000339442.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000339442.jpg  \n",
            "  inflating: data/images/train/000000370042.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000370042.jpg  \n",
            "  inflating: data/images/train/000000389381.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000389381.jpg  \n",
            "  inflating: data/images/train/000000028285.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000028285.jpg  \n",
            "  inflating: data/images/train/000000095843.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000095843.jpg  \n",
            "  inflating: data/images/train/000000179141.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000179141.jpg  \n",
            "  inflating: data/images/train/000000205542.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000205542.jpg  \n",
            "  inflating: data/images/train/000000022623.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000022623.jpg  \n",
            "  inflating: data/images/train/000000180296.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000180296.jpg  \n",
            "  inflating: data/images/train/000000566282.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000566282.jpg  \n",
            "  inflating: data/images/train/000000581357.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000581357.jpg  \n",
            "  inflating: data/images/train/000000289222.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000289222.jpg  \n",
            "  inflating: data/images/train/000000218249.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000218249.jpg  \n",
            "  inflating: data/images/train/000000415536.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000415536.jpg  \n",
            "  inflating: data/images/train/000000547502.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000547502.jpg  \n",
            "  inflating: data/images/train/000000331817.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000331817.jpg  \n",
            "  inflating: data/images/train/000000288882.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000288882.jpg  \n",
            "  inflating: data/images/train/000000329080.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000329080.jpg  \n",
            "  inflating: data/images/train/000000301718.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000301718.jpg  \n",
            "  inflating: data/images/train/000000216516.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000216516.jpg  \n",
            "  inflating: data/images/train/000000486438.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000486438.jpg  \n",
            "  inflating: data/images/train/000000539962.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000539962.jpg  \n",
            "  inflating: data/images/train/000000357238.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000357238.jpg  \n",
            "  inflating: data/images/train/000000233033.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000233033.jpg  \n",
            "  inflating: data/images/train/000000022192.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000022192.jpg  \n",
            "  inflating: data/images/train/000000089271.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000089271.jpg  \n",
            "  inflating: data/images/train/000000001993.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000001993.jpg  \n",
            "  inflating: data/images/train/000000348481.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000348481.jpg  \n",
            "  inflating: data/images/train/000000526103.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000526103.jpg  \n",
            "  inflating: data/images/train/000000154004.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000154004.jpg  \n",
            "  inflating: data/images/train/000000186624.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186624.jpg  \n",
            "  inflating: data/images/train/000000576052.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000576052.jpg  \n",
            "  inflating: data/images/train/000000134096.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000134096.jpg  \n",
            "  inflating: data/images/train/000000266768.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000266768.jpg  \n",
            "  inflating: data/images/train/000000554595.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000554595.jpg  \n",
            "  inflating: data/images/train/000000559099.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000559099.jpg  \n",
            "  inflating: data/images/train/000000017115.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000017115.jpg  \n",
            "  inflating: data/images/train/000000270122.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000270122.jpg  \n",
            "  inflating: data/images/train/000000360325.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000360325.jpg  \n",
            "  inflating: data/images/train/000000565012.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000565012.jpg  \n",
            "  inflating: data/images/train/000000129945.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000129945.jpg  \n",
            "  inflating: data/images/train/000000008021.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000008021.jpg  \n",
            "  inflating: data/images/train/000000334006.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000334006.jpg  \n",
            "  inflating: data/images/train/000000500477.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500477.jpg  \n",
            "  inflating: data/images/train/000000456143.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000456143.jpg  \n",
            "  inflating: data/images/train/000000034257.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000034257.jpg  \n",
            "  inflating: data/images/train/000000107851.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000107851.jpg  \n",
            "  inflating: data/images/train/000000293044.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000293044.jpg  \n",
            "  inflating: data/images/train/000000166277.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000166277.jpg  \n",
            "  inflating: data/images/train/000000319369.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000319369.jpg  \n",
            "  inflating: data/images/train/000000352618.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000352618.jpg  \n",
            "  inflating: data/images/train/000000143961.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000143961.jpg  \n",
            "  inflating: data/images/train/000000357748.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000357748.jpg  \n",
            "  inflating: data/images/train/000000297578.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297578.jpg  \n",
            "  inflating: data/images/train/000000146831.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000146831.jpg  \n",
            "  inflating: data/images/train/000000200162.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000200162.jpg  \n",
            "  inflating: data/images/train/000000144798.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000144798.jpg  \n",
            "  inflating: data/images/train/000000410880.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000410880.jpg  \n",
            "  inflating: data/images/train/000000278973.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000278973.jpg  \n",
            "  inflating: data/images/train/000000273198.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000273198.jpg  \n",
            "  inflating: data/images/train/000000157928.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000157928.jpg  \n",
            "  inflating: data/images/train/000000146825.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000146825.jpg  \n",
            "  inflating: data/images/train/000000080057.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000080057.jpg  \n",
            "  inflating: data/images/train/000000393093.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000393093.jpg  \n",
            "  inflating: data/images/train/000000232649.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000232649.jpg  \n",
            "  inflating: data/images/train/000000059044.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000059044.jpg  \n",
            "  inflating: data/images/train/000000403817.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000403817.jpg  \n",
            "  inflating: data/images/train/000000026690.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000026690.jpg  \n",
            "  inflating: data/images/train/000000484978.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000484978.jpg  \n",
            "  inflating: data/images/train/000000417876.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000417876.jpg  \n",
            "  inflating: data/images/train/000000191614.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000191614.jpg  \n",
            "  inflating: data/images/train/000000379476.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000379476.jpg  \n",
            "  inflating: data/images/train/000000138492.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000138492.jpg  \n",
            "  inflating: data/images/train/000000088345.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000088345.jpg  \n",
            "  inflating: data/images/train/000000426329.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000426329.jpg  \n",
            "  inflating: data/images/train/000000015272.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000015272.jpg  \n",
            "  inflating: data/images/train/000000060835.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060835.jpg  \n",
            "  inflating: data/images/train/000000071938.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000071938.jpg  \n",
            "  inflating: data/images/train/000000338428.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000338428.jpg  \n",
            "  inflating: data/images/train/000000052891.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000052891.jpg  \n",
            "  inflating: data/images/train/000000485480.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000485480.jpg  \n",
            "  inflating: data/images/train/000000060823.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060823.jpg  \n",
            "  inflating: data/images/train/000000049269.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000049269.jpg  \n",
            "  inflating: data/images/train/000000260657.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000260657.jpg  \n",
            "  inflating: data/images/train/000000039956.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000039956.jpg  \n",
            "  inflating: data/images/train/000000041635.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000041635.jpg  \n",
            "  inflating: data/images/train/000000067180.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000067180.jpg  \n",
            "  inflating: data/images/train/000000032817.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000032817.jpg  \n",
            "  inflating: data/images/train/000000057725.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000057725.jpg  \n",
            "  inflating: data/images/train/000000273617.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000273617.jpg  \n",
            "  inflating: data/images/train/000000144003.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000144003.jpg  \n",
            "  inflating: data/images/train/000000142472.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000142472.jpg  \n",
            "  inflating: data/images/train/000000222458.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000222458.jpg  \n",
            "  inflating: data/images/train/000000553788.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000553788.jpg  \n",
            "  inflating: data/images/train/000000194746.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000194746.jpg  \n",
            "  inflating: data/images/train/000000337055.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000337055.jpg  \n",
            "  inflating: data/images/train/000000318908.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000318908.jpg  \n",
            "  inflating: data/images/train/000000370478.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000370478.jpg  \n",
            "  inflating: data/images/train/000000128654.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000128654.jpg  \n",
            "  inflating: data/images/train/000000000872.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000000872.jpg  \n",
            "  inflating: data/images/train/000000527784.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000527784.jpg  \n",
            "  inflating: data/images/train/000000509451.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000509451.jpg  \n",
            "  inflating: data/images/train/000000064462.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000064462.jpg  \n",
            "  inflating: data/images/train/000000350019.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000350019.jpg  \n",
            "  inflating: data/images/train/000000545129.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000545129.jpg  \n",
            "  inflating: data/images/train/000000459272.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000459272.jpg  \n",
            "  inflating: data/images/train/000000455448.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000455448.jpg  \n",
            "  inflating: data/images/train/000000237928.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000237928.jpg  \n",
            "  inflating: data/images/train/000000433915.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000433915.jpg  \n",
            "  inflating: data/images/train/000000506004.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000506004.jpg  \n",
            "  inflating: data/images/train/000000480275.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000480275.jpg  \n",
            "  inflating: data/images/train/000000126137.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000126137.jpg  \n",
            "  inflating: data/images/train/000000459500.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000459500.jpg  \n",
            "  inflating: data/images/train/000000527960.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000527960.jpg  \n",
            "  inflating: data/images/train/000000061268.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000061268.jpg  \n",
            "  inflating: data/images/train/000000104619.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000104619.jpg  \n",
            "  inflating: data/images/train/000000163682.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000163682.jpg  \n",
            "  inflating: data/images/train/000000309391.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000309391.jpg  \n",
            "  inflating: data/images/train/000000329041.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000329041.jpg  \n",
            "  inflating: data/images/train/000000275058.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000275058.jpg  \n",
            "  inflating: data/images/train/000000342186.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000342186.jpg  \n",
            "  inflating: data/images/train/000000113403.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000113403.jpg  \n",
            "  inflating: data/images/train/000000443969.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000443969.jpg  \n",
            "  inflating: data/images/train/000000529568.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000529568.jpg  \n",
            "  inflating: data/images/train/000000001761.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000001761.jpg  \n",
            "  inflating: data/images/train/000000480936.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000480936.jpg  \n",
            "  inflating: data/images/train/000000146358.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000146358.jpg  \n",
            "  inflating: data/images/train/000000565776.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000565776.jpg  \n",
            "  inflating: data/images/train/000000203864.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000203864.jpg  \n",
            "  inflating: data/images/train/000000042102.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000042102.jpg  \n",
            "  inflating: data/images/train/000000084031.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000084031.jpg  \n",
            "  inflating: data/images/train/000000227044.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000227044.jpg  \n",
            "  inflating: data/images/train/000000186632.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186632.jpg  \n",
            "  inflating: data/images/train/000000291490.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000291490.jpg  \n",
            "  inflating: data/images/train/000000105249.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000105249.jpg  \n",
            "  inflating: data/images/train/000000068933.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000068933.jpg  \n",
            "  inflating: data/images/train/000000462031.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000462031.jpg  \n",
            "  inflating: data/images/train/000000002532.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000002532.jpg  \n",
            "  inflating: data/images/train/000000456394.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000456394.jpg  \n",
            "  inflating: data/images/train/000000569825.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000569825.jpg  \n",
            "  inflating: data/images/train/000000153782.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000153782.jpg  \n",
            "  inflating: data/images/train/000000029984.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000029984.jpg  \n",
            "  inflating: data/images/train/000000473869.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000473869.jpg  \n",
            "  inflating: data/images/train/000000259571.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000259571.jpg  \n",
            "  inflating: data/images/train/000000137576.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000137576.jpg  \n",
            "  inflating: data/images/train/000000290771.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000290771.jpg  \n",
            "  inflating: data/images/train/000000154947.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000154947.jpg  \n",
            "  inflating: data/images/train/000000504439.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000504439.jpg  \n",
            "  inflating: data/images/train/000000414170.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000414170.jpg  \n",
            "  inflating: data/images/train/000000297022.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297022.jpg  \n",
            "  inflating: data/images/train/000000097924.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000097924.jpg  \n",
            "  inflating: data/images/train/000000500663.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500663.jpg  \n",
            "  inflating: data/images/train/000000425226.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000425226.jpg  \n",
            "  inflating: data/images/train/000000087470.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000087470.jpg  \n",
            "  inflating: data/images/train/000000054628.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000054628.jpg  \n",
            "  inflating: data/images/train/000000563267.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000563267.jpg  \n",
            "  inflating: data/images/train/000000338986.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000338986.jpg  \n",
            "  inflating: data/images/train/000000480842.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000480842.jpg  \n",
            "  inflating: data/images/train/000000434459.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000434459.jpg  \n",
            "  inflating: data/images/train/000000015660.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000015660.jpg  \n",
            "  inflating: data/images/train/000000468332.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000468332.jpg  \n",
            "  inflating: data/images/train/000000235252.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000235252.jpg  \n",
            "  inflating: data/images/train/000000471893.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000471893.jpg  \n",
            "  inflating: data/images/train/000000189475.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000189475.jpg  \n",
            "  inflating: data/images/train/000000550691.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000550691.jpg  \n",
            "  inflating: data/images/train/000000366178.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000366178.jpg  \n",
            "  inflating: data/images/train/000000110042.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000110042.jpg  \n",
            "  inflating: data/images/train/000000099114.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000099114.jpg  \n",
            "  inflating: data/images/train/000000130386.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000130386.jpg  \n",
            "  inflating: data/images/train/000000571893.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000571893.jpg  \n",
            "  inflating: data/images/train/000000514979.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000514979.jpg  \n",
            "  inflating: data/images/train/000000063047.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000063047.jpg  \n",
            "  inflating: data/images/train/000000121506.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000121506.jpg  \n",
            "  inflating: data/images/train/000000290163.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000290163.jpg  \n",
            "  inflating: data/images/train/000000065350.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000065350.jpg  \n",
            "  inflating: data/images/train/000000533493.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000533493.jpg  \n",
            "  inflating: data/images/train/000000262487.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000262487.jpg  \n",
            "  inflating: data/images/train/000000455716.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000455716.jpg  \n",
            "  inflating: data/images/train/000000396274.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000396274.jpg  \n",
            "  inflating: data/images/train/000000384670.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000384670.jpg  \n",
            "  inflating: data/images/train/000000124442.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000124442.jpg  \n",
            "  inflating: data/images/train/000000317024.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000317024.jpg  \n",
            "  inflating: data/images/train/000000459662.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000459662.jpg  \n",
            "  inflating: data/images/train/000000263969.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000263969.jpg  \n",
            "  inflating: data/images/train/000000214539.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000214539.jpg  \n",
            "  inflating: data/images/train/000000251065.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000251065.jpg  \n",
            "  inflating: data/images/train/000000293324.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000293324.jpg  \n",
            "  inflating: data/images/train/000000201646.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000201646.jpg  \n",
            "  inflating: data/images/train/000000288062.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000288062.jpg  \n",
            "  inflating: data/images/train/000000410510.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000410510.jpg  \n",
            "  inflating: data/images/train/000000022755.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000022755.jpg  \n",
            "  inflating: data/images/train/000000299609.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000299609.jpg  \n",
            "  inflating: data/images/train/000000088970.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000088970.jpg  \n",
            "  inflating: data/images/train/000000069224.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000069224.jpg  \n",
            "  inflating: data/images/train/000000077595.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000077595.jpg  \n",
            "  inflating: data/images/train/000000341921.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000341921.jpg  \n",
            "  inflating: data/images/train/000000176847.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000176847.jpg  \n",
            "  inflating: data/images/train/000000468124.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000468124.jpg  \n",
            "  inflating: data/images/train/000000154358.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000154358.jpg  \n",
            "  inflating: data/images/train/000000571313.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000571313.jpg  \n",
            "  inflating: data/images/train/000000234366.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000234366.jpg  \n",
            "  inflating: data/images/train/000000329323.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000329323.jpg  \n",
            "  inflating: data/images/train/000000433134.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000433134.jpg  \n",
            "  inflating: data/images/train/000000338560.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000338560.jpg  \n",
            "  inflating: data/images/train/000000102644.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000102644.jpg  \n",
            "  inflating: data/images/train/000000180135.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000180135.jpg  \n",
            "  inflating: data/images/train/000000015338.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000015338.jpg  \n",
            "  inflating: data/images/train/000000534673.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000534673.jpg  \n",
            "  inflating: data/images/train/000000119516.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000119516.jpg  \n",
            "  inflating: data/images/train/000000286503.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000286503.jpg  \n",
            "  inflating: data/images/train/000000138241.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000138241.jpg  \n",
            "  inflating: data/images/train/000000505451.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000505451.jpg  \n",
            "  inflating: data/images/train/000000412887.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000412887.jpg  \n",
            "  inflating: data/images/train/000000302165.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000302165.jpg  \n",
            "  inflating: data/images/train/000000463918.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000463918.jpg  \n",
            "  inflating: data/images/train/000000334399.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000334399.jpg  \n",
            "  inflating: data/images/train/000000492077.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000492077.jpg  \n",
            "  inflating: data/images/train/000000060770.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060770.jpg  \n",
            "  inflating: data/images/train/000000550322.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000550322.jpg  \n",
            "  inflating: data/images/train/000000295231.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000295231.jpg  \n",
            "  inflating: data/images/train/000000547886.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000547886.jpg  \n",
            "  inflating: data/images/train/000000397354.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000397354.jpg  \n",
            "  inflating: data/images/train/000000517069.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000517069.jpg  \n",
            "  inflating: data/images/train/000000358525.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000358525.jpg  \n",
            "  inflating: data/images/train/000000129416.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000129416.jpg  \n",
            "  inflating: data/images/train/000000184384.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000184384.jpg  \n",
            "  inflating: data/images/train/000000410712.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000410712.jpg  \n",
            "  inflating: data/images/train/000000297427.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297427.jpg  \n",
            "  inflating: data/images/train/000000227482.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000227482.jpg  \n",
            "  inflating: data/images/train/000000323828.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000323828.jpg  \n",
            "  inflating: data/images/train/000000034452.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000034452.jpg  \n",
            "  inflating: data/images/train/000000339870.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000339870.jpg  \n",
            "  inflating: data/images/train/000000223182.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000223182.jpg  \n",
            "  inflating: data/images/train/000000043816.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000043816.jpg  \n",
            "  inflating: data/images/train/000000110282.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000110282.jpg  \n",
            "  inflating: data/images/train/000000348045.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000348045.jpg  \n",
            "  inflating: data/images/train/000000504000.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000504000.jpg  \n",
            "  inflating: data/images/train/000000198960.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000198960.jpg  \n",
            "  inflating: data/images/train/000000219578.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000219578.jpg  \n",
            "  inflating: data/images/train/000000318114.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000318114.jpg  \n",
            "  inflating: data/images/train/000000148957.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000148957.jpg  \n",
            "  inflating: data/images/train/000000035770.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000035770.jpg  \n",
            "  inflating: data/images/train/000000125211.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125211.jpg  \n",
            "  inflating: data/images/train/000000173057.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000173057.jpg  \n",
            "  inflating: data/images/train/000000364587.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000364587.jpg  \n",
            "  inflating: data/images/train/000000455267.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000455267.jpg  \n",
            "  inflating: data/images/train/000000209757.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000209757.jpg  \n",
            "  inflating: data/images/train/000000497867.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000497867.jpg  \n",
            "  inflating: data/images/train/000000554838.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000554838.jpg  \n",
            "  inflating: data/images/train/000000570756.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000570756.jpg  \n",
            "  inflating: data/images/train/000000078843.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000078843.jpg  \n",
            "  inflating: data/images/train/000000266409.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000266409.jpg  \n",
            "  inflating: data/images/train/000000309964.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000309964.jpg  \n",
            "  inflating: data/images/train/000000297396.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297396.jpg  \n",
            "  inflating: data/images/train/000000429623.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000429623.jpg  \n",
            "  inflating: data/images/train/000000535578.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000535578.jpg  \n",
            "  inflating: data/images/train/000000231237.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000231237.jpg  \n",
            "  inflating: data/images/train/000000013774.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000013774.jpg  \n",
            "  inflating: data/images/train/000000410934.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000410934.jpg  \n",
            "  inflating: data/images/train/000000492937.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000492937.jpg  \n",
            "  inflating: data/images/train/000000563702.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000563702.jpg  \n",
            "  inflating: data/images/train/000000301135.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000301135.jpg  \n",
            "  inflating: data/images/train/000000180487.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000180487.jpg  \n",
            "  inflating: data/images/train/000000070774.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000070774.jpg  \n",
            "  inflating: data/images/train/000000486573.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000486573.jpg  \n",
            "  inflating: data/images/train/000000500716.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500716.jpg  \n",
            "  inflating: data/images/train/000000166664.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000166664.jpg  \n",
            "  inflating: data/images/train/000000051976.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000051976.jpg  \n",
            "  inflating: data/images/train/000000113589.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000113589.jpg  \n",
            "  inflating: data/images/train/000000151962.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000151962.jpg  \n",
            "  inflating: data/images/train/000000370900.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000370900.jpg  \n",
            "  inflating: data/images/train/000000347174.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000347174.jpg  \n",
            "  inflating: data/images/train/000000451571.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000451571.jpg  \n",
            "  inflating: data/images/train/000000447313.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000447313.jpg  \n",
            "  inflating: data/images/train/000000229849.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000229849.jpg  \n",
            "  inflating: data/images/train/000000557672.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000557672.jpg  \n",
            "  inflating: data/images/train/000000165351.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000165351.jpg  \n",
            "  inflating: data/images/train/000000181969.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000181969.jpg  \n",
            "  inflating: data/images/train/000000524850.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000524850.jpg  \n",
            "  inflating: data/images/train/000000073533.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000073533.jpg  \n",
            "  inflating: data/images/train/000000459887.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000459887.jpg  \n",
            "  inflating: data/images/train/000000210789.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000210789.jpg  \n",
            "  inflating: data/images/train/000000295797.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000295797.jpg  \n",
            "  inflating: data/images/train/000000231747.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000231747.jpg  \n",
            "  inflating: data/images/train/000000125952.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125952.jpg  \n",
            "  inflating: data/images/train/000000387387.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000387387.jpg  \n",
            "  inflating: data/images/train/000000248284.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000248284.jpg  \n",
            "  inflating: data/images/train/000000342971.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000342971.jpg  \n",
            "  inflating: data/images/train/000000278353.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000278353.jpg  \n",
            "  inflating: data/images/train/000000115885.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000115885.jpg  \n",
            "  inflating: data/images/train/000000526706.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000526706.jpg  \n",
            "  inflating: data/images/train/000000238039.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000238039.jpg  \n",
            "  inflating: data/images/train/000000095707.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000095707.jpg  \n",
            "  inflating: data/images/train/000000561465.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000561465.jpg  \n",
            "  inflating: data/images/train/000000546964.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000546964.jpg  \n",
            "  inflating: data/images/train/000000494188.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000494188.jpg  \n",
            "  inflating: data/images/train/000000476119.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000476119.jpg  \n",
            "  inflating: data/images/train/000000244496.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000244496.jpg  \n",
            "  inflating: data/images/train/000000425227.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000425227.jpg  \n",
            "  inflating: data/images/train/000000405691.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000405691.jpg  \n",
            "  inflating: data/images/train/000000081766.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000081766.jpg  \n",
            "  inflating: data/images/train/000000038678.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000038678.jpg  \n",
            "  inflating: data/images/train/000000442323.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000442323.jpg  \n",
            "  inflating: data/images/train/000000213445.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213445.jpg  \n",
            "  inflating: data/images/train/000000537964.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000537964.jpg  \n",
            "  inflating: data/images/train/000000489046.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000489046.jpg  \n",
            "  inflating: data/images/train/000000293245.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000293245.jpg  \n",
            "  inflating: data/images/train/000000551439.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000551439.jpg  \n",
            "  inflating: data/images/train/000000568290.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000568290.jpg  \n",
            "  inflating: data/images/train/000000164885.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000164885.jpg  \n",
            "  inflating: data/images/train/000000494759.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000494759.jpg  \n",
            "  inflating: data/images/train/000000356125.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000356125.jpg  \n",
            "  inflating: data/images/train/000000440508.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000440508.jpg  \n",
            "  inflating: data/images/train/000000286660.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000286660.jpg  \n",
            "  inflating: data/images/train/000000153797.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000153797.jpg  \n",
            "  inflating: data/images/train/000000104803.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000104803.jpg  \n",
            "  inflating: data/images/train/000000558421.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000558421.jpg  \n",
            "  inflating: data/images/train/000000425390.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000425390.jpg  \n",
            "  inflating: data/images/train/000000163640.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000163640.jpg  \n",
            "  inflating: data/images/train/000000368961.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000368961.jpg  \n",
            "  inflating: data/images/train/000000118594.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000118594.jpg  \n",
            "  inflating: data/images/train/000000489091.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000489091.jpg  \n",
            "  inflating: data/images/train/000000462756.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000462756.jpg  \n",
            "  inflating: data/images/train/000000538458.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000538458.jpg  \n",
            "  inflating: data/images/train/000000182441.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000182441.jpg  \n",
            "  inflating: data/images/train/000000052462.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000052462.jpg  \n",
            "  inflating: data/images/train/000000368752.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000368752.jpg  \n",
            "  inflating: data/images/train/000000466256.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000466256.jpg  \n",
            "  inflating: data/images/train/000000107339.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000107339.jpg  \n",
            "  inflating: data/images/train/000000566524.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000566524.jpg  \n",
            "  inflating: data/images/train/000000279887.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000279887.jpg  \n",
            "  inflating: data/images/train/000000155443.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000155443.jpg  \n",
            "  inflating: data/images/train/000000433243.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000433243.jpg  \n",
            "  inflating: data/images/train/000000231169.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000231169.jpg  \n",
            "  inflating: data/images/train/000000116208.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000116208.jpg  \n",
            "  inflating: data/images/train/000000377882.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000377882.jpg  \n",
            "  inflating: data/images/train/000000269316.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000269316.jpg  \n",
            "  inflating: data/images/train/000000428111.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000428111.jpg  \n",
            "  inflating: data/images/train/000000504389.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000504389.jpg  \n",
            "  inflating: data/images/train/000000176701.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000176701.jpg  \n",
            "  inflating: data/images/train/000000439593.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000439593.jpg  \n",
            "  inflating: data/images/train/000000020553.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000020553.jpg  \n",
            "  inflating: data/images/train/000000484760.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000484760.jpg  \n",
            "  inflating: data/images/train/000000332845.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000332845.jpg  \n",
            "  inflating: data/images/train/000000105923.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000105923.jpg  \n",
            "  inflating: data/images/train/000000482477.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000482477.jpg  \n",
            "  inflating: data/images/train/000000212559.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000212559.jpg  \n",
            "  inflating: data/images/train/000000090284.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000090284.jpg  \n",
            "  inflating: data/images/train/000000518213.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000518213.jpg  \n",
            "  inflating: data/images/train/000000545100.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000545100.jpg  \n",
            "  inflating: data/images/train/000000483999.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000483999.jpg  \n",
            "  inflating: data/images/train/000000370486.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000370486.jpg  \n",
            "  inflating: data/images/train/000000283268.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000283268.jpg  \n",
            "  inflating: data/images/train/000000488166.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000488166.jpg  \n",
            "  inflating: data/images/train/000000384513.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000384513.jpg  \n",
            "  inflating: data/images/train/000000457262.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000457262.jpg  \n",
            "  inflating: data/images/train/000000553776.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000553776.jpg  \n",
            "  inflating: data/images/train/000000135604.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000135604.jpg  \n",
            "  inflating: data/images/train/000000036494.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000036494.jpg  \n",
            "  inflating: data/images/train/000000357978.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000357978.jpg  \n",
            "  inflating: data/images/train/000000140270.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000140270.jpg  \n",
            "  inflating: data/images/train/000000120584.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000120584.jpg  \n",
            "  inflating: data/images/train/000000449909.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000449909.jpg  \n",
            "  inflating: data/images/train/000000197528.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000197528.jpg  \n",
            "  inflating: data/images/train/000000551820.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000551820.jpg  \n",
            "  inflating: data/images/train/000000223747.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000223747.jpg  \n",
            "  inflating: data/images/train/000000465549.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000465549.jpg  \n",
            "  inflating: data/images/train/000000098633.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000098633.jpg  \n",
            "  inflating: data/images/train/000000271997.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000271997.jpg  \n",
            "  inflating: data/images/train/000000226171.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000226171.jpg  \n",
            "  inflating: data/images/train/000000222317.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000222317.jpg  \n",
            "  inflating: data/images/train/000000427034.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000427034.jpg  \n",
            "  inflating: data/images/train/000000015517.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000015517.jpg  \n",
            "  inflating: data/images/train/000000214869.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000214869.jpg  \n",
            "  inflating: data/images/train/000000187990.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000187990.jpg  \n",
            "  inflating: data/images/train/000000329219.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000329219.jpg  \n",
            "  inflating: data/images/train/000000394940.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000394940.jpg  \n",
            "  inflating: data/images/train/000000140203.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000140203.jpg  \n",
            "  inflating: data/images/train/000000084241.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000084241.jpg  \n",
            "  inflating: data/images/train/000000472046.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000472046.jpg  \n",
            "  inflating: data/images/train/000000104455.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000104455.jpg  \n",
            "  inflating: data/images/train/000000545826.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000545826.jpg  \n",
            "  inflating: data/images/train/000000493284.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000493284.jpg  \n",
            "  inflating: data/images/train/000000051326.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000051326.jpg  \n",
            "  inflating: data/images/train/000000124975.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000124975.jpg  \n",
            "  inflating: data/images/train/000000155154.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000155154.jpg  \n",
            "  inflating: data/images/train/000000471567.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000471567.jpg  \n",
            "  inflating: data/images/train/000000176799.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000176799.jpg  \n",
            "  inflating: data/images/train/000000108253.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000108253.jpg  \n",
            "  inflating: data/images/train/000000090208.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000090208.jpg  \n",
            "  inflating: data/images/train/000000429718.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000429718.jpg  \n",
            "  inflating: data/images/train/000000271728.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000271728.jpg  \n",
            "  inflating: data/images/train/000000324715.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000324715.jpg  \n",
            "  inflating: data/images/train/000000487583.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000487583.jpg  \n",
            "  inflating: data/images/train/000000540962.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000540962.jpg  \n",
            "  inflating: data/images/train/000000513484.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000513484.jpg  \n",
            "  inflating: data/images/train/000000347265.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000347265.jpg  \n",
            "  inflating: data/images/train/000000193926.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000193926.jpg  \n",
            "  inflating: data/images/train/000000159791.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000159791.jpg  \n",
            "  inflating: data/images/train/000000106281.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000106281.jpg  \n",
            "  inflating: data/images/train/000000215245.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000215245.jpg  \n",
            "  inflating: data/images/train/000000345466.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000345466.jpg  \n",
            "  inflating: data/images/train/000000571598.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000571598.jpg  \n",
            "  inflating: data/images/train/000000066561.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000066561.jpg  \n",
            "  inflating: data/images/train/000000486104.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000486104.jpg  \n",
            "  inflating: data/images/train/000000309678.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000309678.jpg  \n",
            "  inflating: data/images/train/000000551660.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000551660.jpg  \n",
            "  inflating: data/images/train/000000356432.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000356432.jpg  \n",
            "  inflating: data/images/train/000000274687.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000274687.jpg  \n",
            "  inflating: data/images/train/000000060886.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060886.jpg  \n",
            "  inflating: data/images/train/000000380706.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000380706.jpg  \n",
            "  inflating: data/images/train/000000488673.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000488673.jpg  \n",
            "  inflating: data/images/train/000000382111.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000382111.jpg  \n",
            "  inflating: data/images/train/000000022479.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000022479.jpg  \n",
            "  inflating: data/images/train/000000244750.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000244750.jpg  \n",
            "  inflating: data/images/train/000000555412.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000555412.jpg  \n",
            "  inflating: data/images/train/000000175535.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000175535.jpg  \n",
            "  inflating: data/images/train/000000240250.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000240250.jpg  \n",
            "  inflating: data/images/train/000000563349.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000563349.jpg  \n",
            "  inflating: data/images/train/000000006040.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000006040.jpg  \n",
            "  inflating: data/images/train/000000520264.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000520264.jpg  \n",
            "  inflating: data/images/train/000000550797.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000550797.jpg  \n",
            "  inflating: data/images/train/000000405972.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000405972.jpg  \n",
            "  inflating: data/images/train/000000373315.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000373315.jpg  \n",
            "  inflating: data/images/train/000000177861.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000177861.jpg  \n",
            "  inflating: data/images/train/000000480944.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000480944.jpg  \n",
            "  inflating: data/images/train/000000104119.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000104119.jpg  \n",
            "  inflating: data/images/train/000000161781.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000161781.jpg  \n",
            "  inflating: data/images/train/000000319696.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000319696.jpg  \n",
            "  inflating: data/images/train/000000250282.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000250282.jpg  \n",
            "  inflating: data/images/train/000000256195.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000256195.jpg  \n",
            "  inflating: data/images/train/000000496854.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000496854.jpg  \n",
            "  inflating: data/images/train/000000581482.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000581482.jpg  \n",
            "  inflating: data/images/train/000000394559.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000394559.jpg  \n",
            "  inflating: data/images/train/000000003845.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000003845.jpg  \n",
            "  inflating: data/images/train/000000213422.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213422.jpg  \n",
            "  inflating: data/images/train/000000402774.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000402774.jpg  \n",
            "  inflating: data/images/train/000000370813.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000370813.jpg  \n",
            "  inflating: data/images/train/000000245102.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000245102.jpg  \n",
            "  inflating: data/images/train/000000476787.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000476787.jpg  \n",
            "  inflating: data/images/train/000000165518.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000165518.jpg  \n",
            "  inflating: data/images/train/000000398377.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000398377.jpg  \n",
            "  inflating: data/images/train/000000225184.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000225184.jpg  \n",
            "  inflating: data/images/train/000000460683.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000460683.jpg  \n",
            "  inflating: data/images/train/000000551304.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000551304.jpg  \n",
            "  inflating: data/images/train/000000309452.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000309452.jpg  \n",
            "  inflating: data/images/train/000000445365.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000445365.jpg  \n",
            "  inflating: data/images/train/000000284762.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000284762.jpg  \n",
            "  inflating: data/images/train/000000186873.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186873.jpg  \n",
            "  inflating: data/images/train/000000163155.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000163155.jpg  \n",
            "  inflating: data/images/train/000000212072.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000212072.jpg  \n",
            "  inflating: data/images/train/000000418062.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000418062.jpg  \n",
            "  inflating: data/images/train/000000447200.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000447200.jpg  \n",
            "  inflating: data/images/train/000000424162.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000424162.jpg  \n",
            "  inflating: data/images/train/000000456292.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000456292.jpg  \n",
            "  inflating: data/images/train/000000156071.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000156071.jpg  \n",
            "  inflating: data/images/train/000000052565.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000052565.jpg  \n",
            "  inflating: data/images/train/000000397681.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000397681.jpg  \n",
            "  inflating: data/images/train/000000282298.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000282298.jpg  \n",
            "  inflating: data/images/train/000000164969.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000164969.jpg  \n",
            "  inflating: data/images/train/000000363072.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000363072.jpg  \n",
            "  inflating: data/images/train/000000528980.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000528980.jpg  \n",
            "  inflating: data/images/train/000000383838.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000383838.jpg  \n",
            "  inflating: data/images/train/000000032285.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000032285.jpg  \n",
            "  inflating: data/images/train/000000493864.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000493864.jpg  \n",
            "  inflating: data/images/train/000000326248.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000326248.jpg  \n",
            "  inflating: data/images/train/000000297681.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297681.jpg  \n",
            "  inflating: data/images/train/000000361103.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000361103.jpg  \n",
            "  inflating: data/images/train/000000498919.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000498919.jpg  \n",
            "  inflating: data/images/train/000000133819.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000133819.jpg  \n",
            "  inflating: data/images/train/000000367228.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000367228.jpg  \n",
            "  inflating: data/images/train/000000340697.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000340697.jpg  \n",
            "  inflating: data/images/train/000000166165.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000166165.jpg  \n",
            "  inflating: data/images/train/000000213224.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213224.jpg  \n",
            "  inflating: data/images/train/000000108864.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000108864.jpg  \n",
            "  inflating: data/images/train/000000047801.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000047801.jpg  \n",
            "  inflating: data/images/train/000000398203.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000398203.jpg  \n",
            "  inflating: data/images/train/000000288762.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000288762.jpg  \n",
            "  inflating: data/images/train/000000519208.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000519208.jpg  \n",
            "  inflating: data/images/train/000000214205.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000214205.jpg  \n",
            "  inflating: data/images/train/000000157390.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000157390.jpg  \n",
            "  inflating: data/images/train/000000049810.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000049810.jpg  \n",
            "  inflating: data/images/train/000000292060.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000292060.jpg  \n",
            "  inflating: data/images/train/000000319721.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000319721.jpg  \n",
            "  inflating: data/images/train/000000098287.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000098287.jpg  \n",
            "  inflating: data/images/train/000000156924.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000156924.jpg  \n",
            "  inflating: data/images/train/000000377946.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000377946.jpg  \n",
            "  inflating: data/images/train/000000416885.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000416885.jpg  \n",
            "  inflating: data/images/train/000000523194.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000523194.jpg  \n",
            "  inflating: data/images/train/000000384616.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000384616.jpg  \n",
            "  inflating: data/images/train/000000165336.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000165336.jpg  \n",
            "  inflating: data/images/train/000000313783.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000313783.jpg  \n",
            "  inflating: data/images/train/000000534601.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000534601.jpg  \n",
            "  inflating: data/images/train/000000381587.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000381587.jpg  \n",
            "  inflating: data/images/train/000000373705.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000373705.jpg  \n",
            "  inflating: data/images/train/000000529122.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000529122.jpg  \n",
            "  inflating: data/images/train/000000080153.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000080153.jpg  \n",
            "  inflating: data/images/train/000000383384.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000383384.jpg  \n",
            "  inflating: data/images/train/000000273711.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000273711.jpg  \n",
            "  inflating: data/images/train/000000401862.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000401862.jpg  \n",
            "  inflating: data/images/train/000000311180.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000311180.jpg  \n",
            "  inflating: data/images/train/000000184321.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000184321.jpg  \n",
            "  inflating: data/images/train/000000088269.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000088269.jpg  \n",
            "  inflating: data/images/train/000000312489.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000312489.jpg  \n",
            "  inflating: data/images/train/000000017207.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000017207.jpg  \n",
            "  inflating: data/images/train/000000046048.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000046048.jpg  \n",
            "  inflating: data/images/train/000000535523.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000535523.jpg  \n",
            "  inflating: data/images/train/000000427655.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000427655.jpg  \n",
            "  inflating: data/images/train/000000287874.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000287874.jpg  \n",
            "  inflating: data/images/train/000000336265.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000336265.jpg  \n",
            "  inflating: data/images/train/000000449198.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000449198.jpg  \n",
            "  inflating: data/images/train/000000230166.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000230166.jpg  \n",
            "  inflating: data/images/train/000000512836.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000512836.jpg  \n",
            "  inflating: data/images/train/000000235778.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000235778.jpg  \n",
            "  inflating: data/images/train/000000244181.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000244181.jpg  \n",
            "  inflating: data/images/train/000000377239.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000377239.jpg  \n",
            "  inflating: data/images/train/000000224675.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000224675.jpg  \n",
            "  inflating: data/images/train/000000140439.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000140439.jpg  \n",
            "  inflating: data/images/train/000000400573.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000400573.jpg  \n",
            "  inflating: data/images/train/000000048924.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000048924.jpg  \n",
            "  inflating: data/images/train/000000549167.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000549167.jpg  \n",
            "  inflating: data/images/train/000000499622.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000499622.jpg  \n",
            "  inflating: data/images/train/000000176606.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000176606.jpg  \n",
            "  inflating: data/images/train/000000010583.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000010583.jpg  \n",
            "  inflating: data/images/train/000000350679.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000350679.jpg  \n",
            "  inflating: data/images/train/000000559348.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000559348.jpg  \n",
            "  inflating: data/images/train/000000102805.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000102805.jpg  \n",
            "  inflating: data/images/train/000000568195.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000568195.jpg  \n",
            "  inflating: data/images/train/000000488075.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000488075.jpg  \n",
            "  inflating: data/images/train/000000485237.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000485237.jpg  \n",
            "  inflating: data/images/train/000000545007.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000545007.jpg  \n",
            "  inflating: data/images/train/000000377588.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000377588.jpg  \n",
            "  inflating: data/images/train/000000188296.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000188296.jpg  \n",
            "  inflating: data/images/train/000000031217.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000031217.jpg  \n",
            "  inflating: data/images/train/000000451714.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000451714.jpg  \n",
            "  inflating: data/images/train/000000045596.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000045596.jpg  \n",
            "  inflating: data/images/train/000000250137.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000250137.jpg  \n",
            "  inflating: data/images/train/000000479099.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000479099.jpg  \n",
            "  inflating: data/images/train/000000350122.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000350122.jpg  \n",
            "  inflating: data/images/train/000000078170.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000078170.jpg  \n",
            "  inflating: data/images/train/000000447611.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000447611.jpg  \n",
            "  inflating: data/images/train/000000408112.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000408112.jpg  \n",
            "  inflating: data/images/train/000000145597.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000145597.jpg  \n",
            "  inflating: data/images/train/000000507235.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000507235.jpg  \n",
            "  inflating: data/images/train/000000398028.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000398028.jpg  \n",
            "  inflating: data/images/train/000000534827.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000534827.jpg  \n",
            "  inflating: data/images/train/000000553664.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000553664.jpg  \n",
            "  inflating: data/images/train/000000478393.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000478393.jpg  \n",
            "  inflating: data/images/train/000000492992.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000492992.jpg  \n",
            "  inflating: data/images/train/000000251572.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000251572.jpg  \n",
            "  inflating: data/images/train/000000174004.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000174004.jpg  \n",
            "  inflating: data/images/train/000000409542.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000409542.jpg  \n",
            "  inflating: data/images/train/000000000785.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000000785.jpg  \n",
            "  inflating: data/images/train/000000213033.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213033.jpg  \n",
            "  inflating: data/images/train/000000245513.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000245513.jpg  \n",
            "  inflating: data/images/train/000000203546.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000203546.jpg  \n",
            "  inflating: data/images/train/000000414261.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000414261.jpg  \n",
            "  inflating: data/images/train/000000020333.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000020333.jpg  \n",
            "  inflating: data/images/train/000000397327.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000397327.jpg  \n",
            "  inflating: data/images/train/000000464786.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000464786.jpg  \n",
            "  inflating: data/images/train/000000345261.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000345261.jpg  \n",
            "  inflating: data/images/train/000000057150.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000057150.jpg  \n",
            "  inflating: data/images/train/000000415194.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000415194.jpg  \n",
            "  inflating: data/images/train/000000560279.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000560279.jpg  \n",
            "  inflating: data/images/train/000000322211.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000322211.jpg  \n",
            "  inflating: data/images/train/000000424349.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000424349.jpg  \n",
            "  inflating: data/images/train/000000003501.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000003501.jpg  \n",
            "  inflating: data/images/train/000000052996.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000052996.jpg  \n",
            "  inflating: data/images/train/000000108440.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000108440.jpg  \n",
            "  inflating: data/images/train/000000531036.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000531036.jpg  \n",
            "  inflating: data/images/train/000000521231.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000521231.jpg  \n",
            "  inflating: data/images/train/000000193674.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000193674.jpg  \n",
            "  inflating: data/images/train/000000109992.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000109992.jpg  \n",
            "  inflating: data/images/train/000000513283.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000513283.jpg  \n",
            "  inflating: data/images/train/000000438774.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000438774.jpg  \n",
            "  inflating: data/images/train/000000564023.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000564023.jpg  \n",
            "  inflating: data/images/train/000000058539.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000058539.jpg  \n",
            "  inflating: data/images/train/000000050165.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000050165.jpg  \n",
            "  inflating: data/images/train/000000344816.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000344816.jpg  \n",
            "  inflating: data/images/train/000000179285.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000179285.jpg  \n",
            "  inflating: data/images/train/000000193884.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000193884.jpg  \n",
            "  inflating: data/images/train/000000530466.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000530466.jpg  \n",
            "  inflating: data/images/train/000000368456.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000368456.jpg  \n",
            "  inflating: data/images/train/000000563758.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000563758.jpg  \n",
            "  inflating: data/images/train/000000401446.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000401446.jpg  \n",
            "  inflating: data/images/train/000000145781.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000145781.jpg  \n",
            "  inflating: data/images/train/000000305309.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000305309.jpg  \n",
            "  inflating: data/images/train/000000067534.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000067534.jpg  \n",
            "  inflating: data/images/train/000000070048.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000070048.jpg  \n",
            "  inflating: data/images/train/000000557172.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000557172.jpg  \n",
            "  inflating: data/images/train/000000051938.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000051938.jpg  \n",
            "  inflating: data/images/train/000000163746.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000163746.jpg  \n",
            "  inflating: data/images/train/000000458255.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000458255.jpg  \n",
            "  inflating: data/images/train/000000507037.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000507037.jpg  \n",
            "  inflating: data/images/train/000000047828.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000047828.jpg  \n",
            "  inflating: data/images/train/000000242724.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000242724.jpg  \n",
            "  inflating: data/images/train/000000151938.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000151938.jpg  \n",
            "  inflating: data/images/train/000000185599.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000185599.jpg  \n",
            "  inflating: data/images/train/000000126226.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000126226.jpg  \n",
            "  inflating: data/images/train/000000402615.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000402615.jpg  \n",
            "  inflating: data/images/train/000000455981.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000455981.jpg  \n",
            "  inflating: data/images/train/000000376442.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000376442.jpg  \n",
            "  inflating: data/images/train/000000151051.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000151051.jpg  \n",
            "  inflating: data/images/train/000000292908.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000292908.jpg  \n",
            "  inflating: data/images/train/000000370999.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000370999.jpg  \n",
            "  inflating: data/images/train/000000112626.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000112626.jpg  \n",
            "  inflating: data/images/train/000000084650.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000084650.jpg  \n",
            "  inflating: data/images/train/000000261116.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000261116.jpg  \n",
            "  inflating: data/images/train/000000566436.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000566436.jpg  \n",
            "  inflating: data/images/train/000000149622.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000149622.jpg  \n",
            "  inflating: data/images/train/000000378453.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000378453.jpg  \n",
            "  inflating: data/images/train/000000222991.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000222991.jpg  \n",
            "  inflating: data/images/train/000000452793.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000452793.jpg  \n",
            "  inflating: data/images/train/000000090631.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000090631.jpg  \n",
            "  inflating: data/images/train/000000541664.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000541664.jpg  \n",
            "  inflating: data/images/train/000000066038.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000066038.jpg  \n",
            "  inflating: data/images/train/000000060449.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060449.jpg  \n",
            "  inflating: data/images/train/000000318238.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000318238.jpg  \n",
            "  inflating: data/images/train/000000063154.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000063154.jpg  \n",
            "  inflating: data/images/train/000000483531.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000483531.jpg  \n",
            "  inflating: data/images/train/000000165257.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000165257.jpg  \n",
            "  inflating: data/images/train/000000568584.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000568584.jpg  \n",
            "  inflating: data/images/train/000000057597.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000057597.jpg  \n",
            "  inflating: data/images/train/000000246436.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000246436.jpg  \n",
            "  inflating: data/images/train/000000398438.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000398438.jpg  \n",
            "  inflating: data/images/train/000000033005.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000033005.jpg  \n",
            "  inflating: data/images/train/000000571943.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000571943.jpg  \n",
            "  inflating: data/images/train/000000242678.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000242678.jpg  \n",
            "  inflating: data/images/train/000000460682.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000460682.jpg  \n",
            "  inflating: data/images/train/000000192191.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000192191.jpg  \n",
            "  inflating: data/images/train/000000578967.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000578967.jpg  \n",
            "  inflating: data/images/train/000000544052.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000544052.jpg  \n",
            "  inflating: data/images/train/000000179642.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000179642.jpg  \n",
            "  inflating: data/images/train/000000542423.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000542423.jpg  \n",
            "  inflating: data/images/train/000000446651.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000446651.jpg  \n",
            "  inflating: data/images/train/000000136633.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000136633.jpg  \n",
            "  inflating: data/images/train/000000125129.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125129.jpg  \n",
            "  inflating: data/images/train/000000220764.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000220764.jpg  \n",
            "  inflating: data/images/train/000000369370.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000369370.jpg  \n",
            "  inflating: data/images/train/000000309484.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000309484.jpg  \n",
            "  inflating: data/images/train/000000559956.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000559956.jpg  \n",
            "  inflating: data/images/train/000000538364.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000538364.jpg  \n",
            "  inflating: data/images/train/000000057232.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000057232.jpg  \n",
            "  inflating: data/images/train/000000364126.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000364126.jpg  \n",
            "  inflating: data/images/train/000000151657.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000151657.jpg  \n",
            "  inflating: data/images/train/000000351823.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000351823.jpg  \n",
            "  inflating: data/images/train/000000009400.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000009400.jpg  \n",
            "  inflating: data/images/train/000000335427.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000335427.jpg  \n",
            "  inflating: data/images/train/000000097994.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000097994.jpg  \n",
            "  inflating: data/images/train/000000493905.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000493905.jpg  \n",
            "  inflating: data/images/train/000000205282.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000205282.jpg  \n",
            "  inflating: data/images/train/000000434204.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000434204.jpg  \n",
            "  inflating: data/images/train/000000018519.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000018519.jpg  \n",
            "  inflating: data/images/train/000000324258.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000324258.jpg  \n",
            "  inflating: data/images/train/000000376278.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000376278.jpg  \n",
            "  inflating: data/images/train/000000426166.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000426166.jpg  \n",
            "  inflating: data/images/train/000000232348.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000232348.jpg  \n",
            "  inflating: data/images/train/000000088485.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000088485.jpg  \n",
            "  inflating: data/images/train/000000356427.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000356427.jpg  \n",
            "  inflating: data/images/train/000000295478.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000295478.jpg  \n",
            "  inflating: data/images/train/000000485424.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000485424.jpg  \n",
            "  inflating: data/images/train/000000270386.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000270386.jpg  \n",
            "  inflating: data/images/train/000000164363.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000164363.jpg  \n",
            "  inflating: data/images/train/000000480212.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000480212.jpg  \n",
            "  inflating: data/images/train/000000417608.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000417608.jpg  \n",
            "  inflating: data/images/train/000000223090.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000223090.jpg  \n",
            "  inflating: data/images/train/000000248631.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000248631.jpg  \n",
            "  inflating: data/images/train/000000085823.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000085823.jpg  \n",
            "  inflating: data/images/train/000000082180.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000082180.jpg  \n",
            "  inflating: data/images/train/000000499031.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000499031.jpg  \n",
            "  inflating: data/images/train/000000221693.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000221693.jpg  \n",
            "  inflating: data/images/train/000000391144.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000391144.jpg  \n",
            "  inflating: data/images/train/000000024021.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000024021.jpg  \n",
            "  inflating: data/images/train/000000460494.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000460494.jpg  \n",
            "  inflating: data/images/train/000000020247.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000020247.jpg  \n",
            "  inflating: data/images/train/000000324927.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000324927.jpg  \n",
            "  inflating: data/images/train/000000157756.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000157756.jpg  \n",
            "  inflating: data/images/train/000000563604.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000563604.jpg  \n",
            "  inflating: data/images/train/000000149568.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000149568.jpg  \n",
            "  inflating: data/images/train/000000043737.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000043737.jpg  \n",
            "  inflating: data/images/train/000000147223.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000147223.jpg  \n",
            "  inflating: data/images/train/000000198641.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000198641.jpg  \n",
            "  inflating: data/images/train/000000276720.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000276720.jpg  \n",
            "  inflating: data/images/train/000000323709.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000323709.jpg  \n",
            "  inflating: data/images/train/000000329542.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000329542.jpg  \n",
            "  inflating: data/images/train/000000148662.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000148662.jpg  \n",
            "  inflating: data/images/train/000000289938.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000289938.jpg  \n",
            "  inflating: data/images/train/000000537241.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000537241.jpg  \n",
            "  inflating: data/images/train/000000556873.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000556873.jpg  \n",
            "  inflating: data/images/train/000000146667.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000146667.jpg  \n",
            "  inflating: data/images/train/000000422670.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000422670.jpg  \n",
            "  inflating: data/images/train/000000005992.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000005992.jpg  \n",
            "  inflating: data/images/train/000000263463.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000263463.jpg  \n",
            "  inflating: data/images/train/000000361506.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000361506.jpg  \n",
            "  inflating: data/images/train/000000474344.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000474344.jpg  \n",
            "  inflating: data/images/train/000000000632.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000000632.jpg  \n",
            "  inflating: data/images/train/000000439522.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000439522.jpg  \n",
            "  inflating: data/images/train/000000426372.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000426372.jpg  \n",
            "  inflating: data/images/train/000000230993.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000230993.jpg  \n",
            "  inflating: data/images/train/000000250901.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000250901.jpg  \n",
            "  inflating: data/images/train/000000363461.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000363461.jpg  \n",
            "  inflating: data/images/train/000000182155.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000182155.jpg  \n",
            "  inflating: data/images/train/000000100624.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000100624.jpg  \n",
            "  inflating: data/images/train/000000226883.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000226883.jpg  \n",
            "  inflating: data/images/train/000000322429.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000322429.jpg  \n",
            "  inflating: data/images/train/000000460333.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000460333.jpg  \n",
            "  inflating: data/images/train/000000463174.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000463174.jpg  \n",
            "  inflating: data/images/train/000000041888.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000041888.jpg  \n",
            "  inflating: data/images/train/000000108244.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000108244.jpg  \n",
            "  inflating: data/images/train/000000139099.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000139099.jpg  \n",
            "  inflating: data/images/train/000000431140.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000431140.jpg  \n",
            "  inflating: data/images/train/000000456865.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000456865.jpg  \n",
            "  inflating: data/images/train/000000475064.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000475064.jpg  \n",
            "  inflating: data/images/train/000000135890.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000135890.jpg  \n",
            "  inflating: data/images/train/000000351362.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000351362.jpg  \n",
            "  inflating: data/images/train/000000136355.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000136355.jpg  \n",
            "  inflating: data/images/train/000000458109.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000458109.jpg  \n",
            "  inflating: data/images/train/000000004495.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000004495.jpg  \n",
            "  inflating: data/images/train/000000327592.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000327592.jpg  \n",
            "  inflating: data/images/train/000000291634.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000291634.jpg  \n",
            "  inflating: data/images/train/000000078748.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000078748.jpg  \n",
            "  inflating: data/images/train/000000506707.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000506707.jpg  \n",
            "  inflating: data/images/train/000000151480.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000151480.jpg  \n",
            "  inflating: data/images/train/000000376093.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000376093.jpg  \n",
            "  inflating: data/images/train/000000397279.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000397279.jpg  \n",
            "  inflating: data/images/train/000000219440.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000219440.jpg  \n",
            "  inflating: data/images/train/000000498463.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000498463.jpg  \n",
            "  inflating: data/images/train/000000335800.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000335800.jpg  \n",
            "  inflating: data/images/train/000000073153.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000073153.jpg  \n",
            "  inflating: data/images/train/000000127270.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000127270.jpg  \n",
            "  inflating: data/images/train/000000350054.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000350054.jpg  \n",
            "  inflating: data/images/train/000000167898.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000167898.jpg  \n",
            "  inflating: data/images/train/000000316015.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000316015.jpg  \n",
            "  inflating: data/images/train/000000445602.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000445602.jpg  \n",
            "  inflating: data/images/train/000000380711.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000380711.jpg  \n",
            "  inflating: data/images/train/000000021167.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000021167.jpg  \n",
            "  inflating: data/images/train/000000488664.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000488664.jpg  \n",
            "  inflating: data/images/train/000000109827.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000109827.jpg  \n",
            "  inflating: data/images/train/000000533958.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000533958.jpg  \n",
            "  inflating: data/images/train/000000567886.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000567886.jpg  \n",
            "  inflating: data/images/train/000000261706.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000261706.jpg  \n",
            "  inflating: data/images/train/000000154705.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000154705.jpg  \n",
            "  inflating: data/images/train/000000052412.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000052412.jpg  \n",
            "  inflating: data/images/train/000000297084.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297084.jpg  \n",
            "  inflating: data/images/train/000000210855.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000210855.jpg  \n",
            "  inflating: data/images/train/000000231125.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000231125.jpg  \n",
            "  inflating: data/images/train/000000190753.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000190753.jpg  \n",
            "  inflating: data/images/train/000000261712.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000261712.jpg  \n",
            "  inflating: data/images/train/000000375015.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000375015.jpg  \n",
            "  inflating: data/images/train/000000183049.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000183049.jpg  \n",
            "  inflating: data/images/train/000000155341.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000155341.jpg  \n",
            "  inflating: data/images/train/000000147745.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000147745.jpg  \n",
            "  inflating: data/images/train/000000244592.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000244592.jpg  \n",
            "  inflating: data/images/train/000000430048.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000430048.jpg  \n",
            "  inflating: data/images/train/000000195165.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000195165.jpg  \n",
            "  inflating: data/images/train/000000479448.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000479448.jpg  \n",
            "  inflating: data/images/train/000000575500.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000575500.jpg  \n",
            "  inflating: data/images/train/000000411938.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000411938.jpg  \n",
            "  inflating: data/images/train/000000434548.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000434548.jpg  \n",
            "  inflating: data/images/train/000000145620.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000145620.jpg  \n",
            "  inflating: data/images/train/000000099039.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000099039.jpg  \n",
            "  inflating: data/images/train/000000371529.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000371529.jpg  \n",
            "  inflating: data/images/train/000000459954.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000459954.jpg  \n",
            "  inflating: data/images/train/000000262227.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000262227.jpg  \n",
            "  inflating: data/images/train/000000003661.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000003661.jpg  \n",
            "  inflating: data/images/train/000000085376.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000085376.jpg  \n",
            "  inflating: data/images/train/000000191471.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000191471.jpg  \n",
            "  inflating: data/images/train/000000092839.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000092839.jpg  \n",
            "  inflating: data/images/train/000000236845.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000236845.jpg  \n",
            "  inflating: data/images/train/000000170116.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000170116.jpg  \n",
            "  inflating: data/images/train/000000512564.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000512564.jpg  \n",
            "  inflating: data/images/train/000000170670.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000170670.jpg  \n",
            "  inflating: data/images/train/000000015956.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000015956.jpg  \n",
            "  inflating: data/images/train/000000284991.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000284991.jpg  \n",
            "  inflating: data/images/train/000000414673.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000414673.jpg  \n",
            "  inflating: data/images/train/000000356169.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000356169.jpg  \n",
            "  inflating: data/images/train/000000096493.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000096493.jpg  \n",
            "  inflating: data/images/train/000000515579.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000515579.jpg  \n",
            "  inflating: data/images/train/000000179898.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000179898.jpg  \n",
            "  inflating: data/images/train/000000201025.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000201025.jpg  \n",
            "  inflating: data/images/train/000000146498.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000146498.jpg  \n",
            "  inflating: data/images/train/000000276285.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000276285.jpg  \n",
            "  inflating: data/images/train/000000068765.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000068765.jpg  \n",
            "  inflating: data/images/train/000000266082.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000266082.jpg  \n",
            "  inflating: data/images/train/000000121417.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000121417.jpg  \n",
            "  inflating: data/images/train/000000206831.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000206831.jpg  \n",
            "  inflating: data/images/train/000000577539.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000577539.jpg  \n",
            "  inflating: data/images/train/000000125936.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125936.jpg  \n",
            "  inflating: data/images/train/000000465129.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000465129.jpg  \n",
            "  inflating: data/images/train/000000150417.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000150417.jpg  \n",
            "  inflating: data/images/train/000000152214.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000152214.jpg  \n",
            "  inflating: data/images/train/000000443844.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000443844.jpg  \n",
            "  inflating: data/images/train/000000110999.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000110999.jpg  \n",
            "  inflating: data/images/train/000000407960.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000407960.jpg  \n",
            "  inflating: data/images/train/000000532071.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000532071.jpg  \n",
            "  inflating: data/images/train/000000090155.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000090155.jpg  \n",
            "  inflating: data/images/train/000000395903.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000395903.jpg  \n",
            "  inflating: data/images/train/000000421757.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000421757.jpg  \n",
            "  inflating: data/images/train/000000119995.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000119995.jpg  \n",
            "  inflating: data/images/train/000000058705.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000058705.jpg  \n",
            "  inflating: data/images/train/000000332570.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000332570.jpg  \n",
            "  inflating: data/images/train/000000088040.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000088040.jpg  \n",
            "  inflating: data/images/train/000000072852.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000072852.jpg  \n",
            "  inflating: data/images/train/000000397133.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000397133.jpg  \n",
            "  inflating: data/images/train/000000477288.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000477288.jpg  \n",
            "  inflating: data/images/train/000000286994.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000286994.jpg  \n",
            "  inflating: data/images/train/000000166166.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000166166.jpg  \n",
            "  inflating: data/images/train/000000161609.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000161609.jpg  \n",
            "  inflating: data/images/train/000000416104.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000416104.jpg  \n",
            "  inflating: data/images/train/000000490413.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000490413.jpg  \n",
            "  inflating: data/images/train/000000323496.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000323496.jpg  \n",
            "  inflating: data/images/train/000000412362.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000412362.jpg  \n",
            "  inflating: data/images/train/000000191288.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000191288.jpg  \n",
            "  inflating: data/images/train/000000186938.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186938.jpg  \n",
            "  inflating: data/images/train/000000322944.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000322944.jpg  \n",
            "  inflating: data/images/train/000000221281.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000221281.jpg  \n",
            "  inflating: data/images/train/000000249129.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000249129.jpg  \n",
            "  inflating: data/images/train/000000110972.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000110972.jpg  \n",
            "  inflating: data/images/train/000000508312.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000508312.jpg  \n",
            "  inflating: data/images/train/000000172649.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000172649.jpg  \n",
            "  inflating: data/images/train/000000453302.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000453302.jpg  \n",
            "  inflating: data/images/train/000000127660.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000127660.jpg  \n",
            "  inflating: data/images/train/000000346232.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000346232.jpg  \n",
            "  inflating: data/images/train/000000491725.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000491725.jpg  \n",
            "  inflating: data/images/train/000000396205.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000396205.jpg  \n",
            "  inflating: data/images/train/000000357459.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000357459.jpg  \n",
            "  inflating: data/images/train/000000273712.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000273712.jpg  \n",
            "  inflating: data/images/train/000000042563.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000042563.jpg  \n",
            "  inflating: data/images/train/000000371677.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000371677.jpg  \n",
            "  inflating: data/images/train/000000579070.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000579070.jpg  \n",
            "  inflating: data/images/train/000000453841.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000453841.jpg  \n",
            "  inflating: data/images/train/000000530470.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000530470.jpg  \n",
            "  inflating: data/images/train/000000422706.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000422706.jpg  \n",
            "  inflating: data/images/train/000000182021.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000182021.jpg  \n",
            "  inflating: data/images/train/000000002153.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000002153.jpg  \n",
            "  inflating: data/images/train/000000085772.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000085772.jpg  \n",
            "  inflating: data/images/train/000000429109.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000429109.jpg  \n",
            "  inflating: data/images/train/000000478420.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000478420.jpg  \n",
            "  inflating: data/images/train/000000533145.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000533145.jpg  \n",
            "  inflating: data/images/train/000000419974.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000419974.jpg  \n",
            "  inflating: data/images/train/000000239627.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000239627.jpg  \n",
            "  inflating: data/images/train/000000060932.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060932.jpg  \n",
            "  inflating: data/images/train/000000515828.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000515828.jpg  \n",
            "  inflating: data/images/train/000000005600.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000005600.jpg  \n",
            "  inflating: data/images/train/000000342295.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000342295.jpg  \n",
            "  inflating: data/images/train/000000374727.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000374727.jpg  \n",
            "  inflating: data/images/train/000000302882.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000302882.jpg  \n",
            "  inflating: data/images/train/000000208363.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000208363.jpg  \n",
            "  inflating: data/images/train/000000235784.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000235784.jpg  \n",
            "  inflating: data/images/train/000000205647.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000205647.jpg  \n",
            "  inflating: data/images/train/000000157807.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000157807.jpg  \n",
            "  inflating: data/images/train/000000429690.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000429690.jpg  \n",
            "  inflating: data/images/train/000000285047.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000285047.jpg  \n",
            "  inflating: data/images/train/000000293625.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000293625.jpg  \n",
            "  inflating: data/images/train/000000568814.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000568814.jpg  \n",
            "  inflating: data/images/train/000000301421.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000301421.jpg  \n",
            "  inflating: data/images/train/000000013923.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000013923.jpg  \n",
            "  inflating: data/images/train/000000032735.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000032735.jpg  \n",
            "  inflating: data/images/train/000000278848.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000278848.jpg  \n",
            "  inflating: data/images/train/000000063552.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000063552.jpg  \n",
            "  inflating: data/images/train/000000406129.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000406129.jpg  \n",
            "  inflating: data/images/train/000000527695.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000527695.jpg  \n",
            "  inflating: data/images/train/000000433192.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000433192.jpg  \n",
            "  inflating: data/images/train/000000267940.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000267940.jpg  \n",
            "  inflating: data/images/train/000000173033.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000173033.jpg  \n",
            "  inflating: data/images/train/000000507223.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000507223.jpg  \n",
            "  inflating: data/images/train/000000075456.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000075456.jpg  \n",
            "  inflating: data/images/train/000000243148.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000243148.jpg  \n",
            "  inflating: data/images/train/000000298994.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000298994.jpg  \n",
            "  inflating: data/images/train/000000493442.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000493442.jpg  \n",
            "  inflating: data/images/train/000000330818.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000330818.jpg  \n",
            "  inflating: data/images/train/000000488710.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000488710.jpg  \n",
            "  inflating: data/images/train/000000294162.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000294162.jpg  \n",
            "  inflating: data/images/train/000000548246.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000548246.jpg  \n",
            "  inflating: data/images/train/000000127476.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000127476.jpg  \n",
            "  inflating: data/images/train/000000108495.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000108495.jpg  \n",
            "  inflating: data/images/train/000000513524.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000513524.jpg  \n",
            "  inflating: data/images/train/000000319534.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000319534.jpg  \n",
            "  inflating: data/images/train/000000294163.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000294163.jpg  \n",
            "  inflating: data/images/train/000000374083.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000374083.jpg  \n",
            "  inflating: data/images/train/000000037670.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000037670.jpg  \n",
            "  inflating: data/images/train/000000359677.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000359677.jpg  \n",
            "  inflating: data/images/train/000000394611.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000394611.jpg  \n",
            "  inflating: data/images/train/000000349302.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000349302.jpg  \n",
            "  inflating: data/images/train/000000257896.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000257896.jpg  \n",
            "  inflating: data/images/train/000000343149.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000343149.jpg  \n",
            "  inflating: data/images/train/000000094871.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000094871.jpg  \n",
            "  inflating: data/images/train/000000189820.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000189820.jpg  \n",
            "  inflating: data/images/train/000000230819.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000230819.jpg  \n",
            "  inflating: data/images/train/000000175443.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000175443.jpg  \n",
            "  inflating: data/images/train/000000160728.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000160728.jpg  \n",
            "  inflating: data/images/train/000000351559.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000351559.jpg  \n",
            "  inflating: data/images/train/000000525083.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000525083.jpg  \n",
            "  inflating: data/images/train/000000458054.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000458054.jpg  \n",
            "  inflating: data/images/train/000000263299.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000263299.jpg  \n",
            "  inflating: data/images/train/000000500565.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500565.jpg  \n",
            "  inflating: data/images/train/000000197388.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000197388.jpg  \n",
            "  inflating: data/images/train/000000248752.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000248752.jpg  \n",
            "  inflating: data/images/train/000000258541.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000258541.jpg  \n",
            "  inflating: data/images/train/000000449603.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000449603.jpg  \n",
            "  inflating: data/images/train/000000360960.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000360960.jpg  \n",
            "  inflating: data/images/train/000000091921.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000091921.jpg  \n",
            "  inflating: data/images/train/000000084492.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000084492.jpg  \n",
            "  inflating: data/images/train/000000414510.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000414510.jpg  \n",
            "  inflating: data/images/train/000000099428.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000099428.jpg  \n",
            "  inflating: data/images/train/000000142238.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000142238.jpg  \n",
            "  inflating: data/images/train/000000231508.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000231508.jpg  \n",
            "  inflating: data/images/train/000000535253.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000535253.jpg  \n",
            "  inflating: data/images/train/000000468632.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000468632.jpg  \n",
            "  inflating: data/images/train/000000055022.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000055022.jpg  \n",
            "  inflating: data/images/train/000000322574.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000322574.jpg  \n",
            "  inflating: data/images/train/000000521540.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000521540.jpg  \n",
            "  inflating: data/images/train/000000264535.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000264535.jpg  \n",
            "  inflating: data/images/train/000000152771.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000152771.jpg  \n",
            "  inflating: data/images/train/000000377575.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000377575.jpg  \n",
            "  inflating: data/images/train/000000223130.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000223130.jpg  \n",
            "  inflating: data/images/train/000000522713.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000522713.jpg  \n",
            "  inflating: data/images/train/000000052017.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000052017.jpg  \n",
            "  inflating: data/images/train/000000383386.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000383386.jpg  \n",
            "  inflating: data/images/train/000000560911.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000560911.jpg  \n",
            "  inflating: data/images/train/000000125062.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125062.jpg  \n",
            "  inflating: data/images/train/000000316404.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000316404.jpg  \n",
            "  inflating: data/images/train/000000513041.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000513041.jpg  \n",
            "  inflating: data/images/train/000000070739.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000070739.jpg  \n",
            "  inflating: data/images/train/000000018491.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000018491.jpg  \n",
            "  inflating: data/images/train/000000209530.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000209530.jpg  \n",
            "  inflating: data/images/train/000000530854.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000530854.jpg  \n",
            "  inflating: data/images/train/000000172648.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000172648.jpg  \n",
            "  inflating: data/images/train/000000170739.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000170739.jpg  \n",
            "  inflating: data/images/train/000000192964.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000192964.jpg  \n",
            "  inflating: data/images/train/000000039477.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000039477.jpg  \n",
            "  inflating: data/images/train/000000559160.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000559160.jpg  \n",
            "  inflating: data/images/train/000000516677.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000516677.jpg  \n",
            "  inflating: data/images/train/000000383621.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000383621.jpg  \n",
            "  inflating: data/images/train/000000008899.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000008899.jpg  \n",
            "  inflating: data/images/train/000000098520.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000098520.jpg  \n",
            "  inflating: data/images/train/000000532058.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000532058.jpg  \n",
            "  inflating: data/images/train/000000171382.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000171382.jpg  \n",
            "  inflating: data/images/train/000000065485.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000065485.jpg  \n",
            "  inflating: data/images/train/000000561366.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000561366.jpg  \n",
            "  inflating: data/images/train/000000362434.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000362434.jpg  \n",
            "  inflating: data/images/train/000000431545.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000431545.jpg  \n",
            "  inflating: data/images/train/000000507975.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000507975.jpg  \n",
            "  inflating: data/images/train/000000190140.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000190140.jpg  \n",
            "  inflating: data/images/train/000000325031.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000325031.jpg  \n",
            "  inflating: data/images/train/000000311394.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000311394.jpg  \n",
            "  inflating: data/images/train/000000562121.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000562121.jpg  \n",
            "  inflating: data/images/train/000000277005.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000277005.jpg  \n",
            "  inflating: data/images/train/000000094326.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000094326.jpg  \n",
            "  inflating: data/images/train/000000225757.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000225757.jpg  \n",
            "  inflating: data/images/train/000000253819.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000253819.jpg  \n",
            "  inflating: data/images/train/000000459809.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000459809.jpg  \n",
            "  inflating: data/images/train/000000452784.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000452784.jpg  \n",
            "  inflating: data/images/train/000000480985.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000480985.jpg  \n",
            "  inflating: data/images/train/000000410428.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000410428.jpg  \n",
            "  inflating: data/images/train/000000574810.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000574810.jpg  \n",
            "  inflating: data/images/train/000000376284.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000376284.jpg  \n",
            "  inflating: data/images/train/000000553511.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000553511.jpg  \n",
            "  inflating: data/images/train/000000161032.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000161032.jpg  \n",
            "  inflating: data/images/train/000000088848.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000088848.jpg  \n",
            "  inflating: data/images/train/000000402992.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000402992.jpg  \n",
            "  inflating: data/images/train/000000276284.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000276284.jpg  \n",
            "  inflating: data/images/train/000000098497.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000098497.jpg  \n",
            "  inflating: data/images/train/000000252332.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000252332.jpg  \n",
            "  inflating: data/images/train/000000535858.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000535858.jpg  \n",
            "  inflating: data/images/train/000000501243.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000501243.jpg  \n",
            "  inflating: data/images/train/000000500613.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500613.jpg  \n",
            "  inflating: data/images/train/000000325838.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000325838.jpg  \n",
            "  inflating: data/images/train/000000222825.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000222825.jpg  \n",
            "  inflating: data/images/train/000000400161.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000400161.jpg  \n",
            "  inflating: data/images/train/000000129062.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000129062.jpg  \n",
            "  inflating: data/images/train/000000287527.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000287527.jpg  \n",
            "  inflating: data/images/train/000000174371.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000174371.jpg  \n",
            "  inflating: data/images/train/000000215723.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000215723.jpg  \n",
            "  inflating: data/images/train/000000429281.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000429281.jpg  \n",
            "  inflating: data/images/train/000000525322.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000525322.jpg  \n",
            "  inflating: data/images/train/000000481480.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000481480.jpg  \n",
            "  inflating: data/images/train/000000347930.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000347930.jpg  \n",
            "  inflating: data/images/train/000000333069.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000333069.jpg  \n",
            "  inflating: data/images/train/000000104669.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000104669.jpg  \n",
            "  inflating: data/images/train/000000308799.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000308799.jpg  \n",
            "  inflating: data/images/train/000000042628.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000042628.jpg  \n",
            "  inflating: data/images/train/000000485802.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000485802.jpg  \n",
            "  inflating: data/images/train/000000297085.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000297085.jpg  \n",
            "  inflating: data/images/train/000000052413.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000052413.jpg  \n",
            "  inflating: data/images/train/000000429530.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000429530.jpg  \n",
            "  inflating: data/images/train/000000027932.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000027932.jpg  \n",
            "  inflating: data/images/train/000000365207.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000365207.jpg  \n",
            "  inflating: data/images/train/000000233727.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000233727.jpg  \n",
            "  inflating: data/images/train/000000456496.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000456496.jpg  \n",
            "  inflating: data/images/train/000000405970.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000405970.jpg  \n",
            "  inflating: data/images/train/000000579307.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000579307.jpg  \n",
            "  inflating: data/images/train/000000530061.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000530061.jpg  \n",
            "  inflating: data/images/train/000000261061.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000261061.jpg  \n",
            "  inflating: data/images/train/000000125472.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125472.jpg  \n",
            "  inflating: data/images/train/000000499768.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000499768.jpg  \n",
            "  inflating: data/images/train/000000159977.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000159977.jpg  \n",
            "  inflating: data/images/train/000000047585.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000047585.jpg  \n",
            "  inflating: data/images/train/000000144932.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000144932.jpg  \n",
            "  inflating: data/images/train/000000000802.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000000802.jpg  \n",
            "  inflating: data/images/train/000000127517.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000127517.jpg  \n",
            "  inflating: data/images/train/000000280710.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000280710.jpg  \n",
            "  inflating: data/images/train/000000495146.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000495146.jpg  \n",
            "  inflating: data/images/train/000000356424.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000356424.jpg  \n",
            "  inflating: data/images/train/000000304404.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000304404.jpg  \n",
            "  inflating: data/images/train/000000175251.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000175251.jpg  \n",
            "  inflating: data/images/train/000000166563.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000166563.jpg  \n",
            "  inflating: data/images/train/000000086483.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000086483.jpg  \n",
            "  inflating: data/images/train/000000241602.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000241602.jpg  \n",
            "  inflating: data/images/train/000000486112.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000486112.jpg  \n",
            "  inflating: data/images/train/000000439290.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000439290.jpg  \n",
            "  inflating: data/images/train/000000357060.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000357060.jpg  \n",
            "  inflating: data/images/train/000000355677.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000355677.jpg  \n",
            "  inflating: data/images/train/000000543528.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000543528.jpg  \n",
            "  inflating: data/images/train/000000191672.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000191672.jpg  \n",
            "  inflating: data/images/train/000000153527.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000153527.jpg  \n",
            "  inflating: data/images/train/000000579893.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000579893.jpg  \n",
            "  inflating: data/images/train/000000093717.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000093717.jpg  \n",
            "  inflating: data/images/train/000000493286.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000493286.jpg  \n",
            "  inflating: data/images/train/000000193717.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000193717.jpg  \n",
            "  inflating: data/images/train/000000387916.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000387916.jpg  \n",
            "  inflating: data/images/train/000000057027.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000057027.jpg  \n",
            "  inflating: data/images/train/000000399296.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000399296.jpg  \n",
            "  inflating: data/images/train/000000451879.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000451879.jpg  \n",
            "  inflating: data/images/train/000000264441.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000264441.jpg  \n",
            "  inflating: data/images/train/000000265777.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000265777.jpg  \n",
            "  inflating: data/images/train/000000326128.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000326128.jpg  \n",
            "  inflating: data/images/train/000000470121.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000470121.jpg  \n",
            "  inflating: data/images/train/000000087038.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000087038.jpg  \n",
            "  inflating: data/images/train/000000050006.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000050006.jpg  \n",
            "  inflating: data/images/train/000000190236.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000190236.jpg  \n",
            "  inflating: data/images/train/000000325347.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000325347.jpg  \n",
            "  inflating: data/images/train/000000263474.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000263474.jpg  \n",
            "  inflating: data/images/train/000000562243.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000562243.jpg  \n",
            "  inflating: data/images/train/000000014888.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000014888.jpg  \n",
            "  inflating: data/images/train/000000013659.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000013659.jpg  \n",
            "  inflating: data/images/train/000000563603.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000563603.jpg  \n",
            "  inflating: data/images/train/000000578545.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000578545.jpg  \n",
            "  inflating: data/images/train/000000001503.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000001503.jpg  \n",
            "  inflating: data/images/train/000000183500.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000183500.jpg  \n",
            "  inflating: data/images/train/000000427055.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000427055.jpg  \n",
            "  inflating: data/images/train/000000344795.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000344795.jpg  \n",
            "  inflating: data/images/train/000000181303.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000181303.jpg  \n",
            "  inflating: data/images/train/000000276055.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000276055.jpg  \n",
            "  inflating: data/images/train/000000226662.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000226662.jpg  \n",
            "  inflating: data/images/train/000000445834.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000445834.jpg  \n",
            "  inflating: data/images/train/000000574425.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000574425.jpg  \n",
            "  inflating: data/images/train/000000464144.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000464144.jpg  \n",
            "  inflating: data/images/train/000000447789.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000447789.jpg  \n",
            "  inflating: data/images/train/000000439525.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000439525.jpg  \n",
            "  inflating: data/images/train/000000019402.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000019402.jpg  \n",
            "  inflating: data/images/train/000000245448.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000245448.jpg  \n",
            "  inflating: data/images/train/000000182805.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000182805.jpg  \n",
            "  inflating: data/images/train/000000544519.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000544519.jpg  \n",
            "  inflating: data/images/train/000000291619.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000291619.jpg  \n",
            "  inflating: data/images/train/000000021604.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000021604.jpg  \n",
            "  inflating: data/images/train/000000411530.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000411530.jpg  \n",
            "  inflating: data/images/train/000000218997.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000218997.jpg  \n",
            "  inflating: data/images/train/000000050943.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000050943.jpg  \n",
            "  inflating: data/images/train/000000139077.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000139077.jpg  \n",
            "  inflating: data/images/train/000000191845.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000191845.jpg  \n",
            "  inflating: data/images/train/000000315257.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000315257.jpg  \n",
            "  inflating: data/images/train/000000468965.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000468965.jpg  \n",
            "  inflating: data/images/train/000000368294.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000368294.jpg  \n",
            "  inflating: data/images/train/000000410612.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000410612.jpg  \n",
            "  inflating: data/images/train/000000457559.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000457559.jpg  \n",
            "  inflating: data/images/train/000000477689.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000477689.jpg  \n",
            "  inflating: data/images/train/000000060102.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060102.jpg  \n",
            "  inflating: data/images/train/000000529939.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000529939.jpg  \n",
            "  inflating: data/images/train/000000528399.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000528399.jpg  \n",
            "  inflating: data/images/train/000000041872.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000041872.jpg  \n",
            "  inflating: data/images/train/000000400367.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000400367.jpg  \n",
            "  inflating: data/images/train/000000376900.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000376900.jpg  \n",
            "  inflating: data/images/train/000000173383.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000173383.jpg  \n",
            "  inflating: data/images/train/000000491683.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000491683.jpg  \n",
            "  inflating: data/images/train/000000229747.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000229747.jpg  \n",
            "  inflating: data/images/train/000000251824.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000251824.jpg  \n",
            "  inflating: data/images/train/000000147740.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000147740.jpg  \n",
            "  inflating: data/images/train/000000158660.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000158660.jpg  \n",
            "  inflating: data/images/train/000000229753.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000229753.jpg  \n",
            "  inflating: data/images/train/000000047740.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000047740.jpg  \n",
            "  inflating: data/images/train/000000183716.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000183716.jpg  \n",
            "  inflating: data/images/train/000000491867.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000491867.jpg  \n",
            "  inflating: data/images/train/000000321333.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000321333.jpg  \n",
            "  inflating: data/images/train/000000554291.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000554291.jpg  \n",
            "  inflating: data/images/train/000000189213.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000189213.jpg  \n",
            "  inflating: data/images/train/000000363666.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000363666.jpg  \n",
            "  inflating: data/images/train/000000498857.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000498857.jpg  \n",
            "  inflating: data/images/train/000000190756.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000190756.jpg  \n",
            "  inflating: data/images/train/000000424776.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000424776.jpg  \n",
            "  inflating: data/images/train/000000354753.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000354753.jpg  \n",
            "  inflating: data/images/train/000000532855.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000532855.jpg  \n",
            "  inflating: data/images/train/000000229948.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000229948.jpg  \n",
            "  inflating: data/images/train/000000146489.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000146489.jpg  \n",
            "  inflating: data/images/train/000000419408.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000419408.jpg  \n",
            "  inflating: data/images/train/000000368900.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000368900.jpg  \n",
            "  inflating: data/images/train/000000262587.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000262587.jpg  \n",
            "  inflating: data/images/train/000000284764.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000284764.jpg  \n",
            "  inflating: data/images/train/000000389532.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000389532.jpg  \n",
            "  inflating: data/images/train/000000462904.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000462904.jpg  \n",
            "  inflating: data/images/train/000000032334.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000032334.jpg  \n",
            "  inflating: data/images/train/000000473821.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000473821.jpg  \n",
            "  inflating: data/images/train/000000445439.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000445439.jpg  \n",
            "  inflating: data/images/train/000000343561.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000343561.jpg  \n",
            "  inflating: data/images/train/000000066771.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000066771.jpg  \n",
            "  inflating: data/images/train/000000079651.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000079651.jpg  \n",
            "  inflating: data/images/train/000000283037.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000283037.jpg  \n",
            "  inflating: data/images/train/000000414676.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000414676.jpg  \n",
            "  inflating: data/images/train/000000091500.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000091500.jpg  \n",
            "  inflating: data/images/train/000000001675.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000001675.jpg  \n",
            "  inflating: data/images/train/000000230362.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000230362.jpg  \n",
            "  inflating: data/images/train/000000081061.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000081061.jpg  \n",
            "  inflating: data/images/train/000000183104.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000183104.jpg  \n",
            "  inflating: data/images/train/000000187362.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000187362.jpg  \n",
            "  inflating: data/images/train/000000253835.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000253835.jpg  \n",
            "  inflating: data/images/train/000000030494.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000030494.jpg  \n",
            "  inflating: data/images/train/000000462643.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000462643.jpg  \n",
            "  inflating: data/images/train/000000474021.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000474021.jpg  \n",
            "  inflating: data/images/train/000000392933.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000392933.jpg  \n",
            "  inflating: data/images/train/000000378454.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000378454.jpg  \n",
            "  inflating: data/images/train/000000254814.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000254814.jpg  \n",
            "  inflating: data/images/train/000000153669.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000153669.jpg  \n",
            "  inflating: data/images/train/000000094336.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000094336.jpg  \n",
            "  inflating: data/images/train/000000213593.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213593.jpg  \n",
            "  inflating: data/images/train/000000485972.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000485972.jpg  \n",
            "  inflating: data/images/train/000000068833.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000068833.jpg  \n",
            "  inflating: data/images/train/000000125072.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125072.jpg  \n",
            "  inflating: data/images/train/000000300276.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000300276.jpg  \n",
            "  inflating: data/images/train/000000485027.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000485027.jpg  \n",
            "  inflating: data/images/train/000000218439.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000218439.jpg  \n",
            "  inflating: data/images/train/000000396200.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000396200.jpg  \n",
            "  inflating: data/images/train/000000399655.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000399655.jpg  \n",
            "  inflating: data/images/train/000000010977.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000010977.jpg  \n",
            "  inflating: data/images/train/000000505169.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000505169.jpg  \n",
            "  inflating: data/images/train/000000186929.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186929.jpg  \n",
            "  inflating: data/images/train/000000227187.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000227187.jpg  \n",
            "  inflating: data/images/train/000000031749.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000031749.jpg  \n",
            "  inflating: data/images/train/000000033638.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000033638.jpg  \n",
            "  inflating: data/images/train/000000460929.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000460929.jpg  \n",
            "  inflating: data/images/train/000000368684.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000368684.jpg  \n",
            "  inflating: data/images/train/000000281032.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000281032.jpg  \n",
            "  inflating: data/images/train/000000231097.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000231097.jpg  \n",
            "  inflating: data/images/train/000000068628.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000068628.jpg  \n",
            "  inflating: data/images/train/000000076416.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000076416.jpg  \n",
            "  inflating: data/images/train/000000023359.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000023359.jpg  \n",
            "  inflating: data/images/train/000000281754.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000281754.jpg  \n",
            "  inflating: data/images/train/000000161397.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000161397.jpg  \n",
            "  inflating: data/images/train/000000050638.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000050638.jpg  \n",
            "  inflating: data/images/train/000000536038.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000536038.jpg  \n",
            "  inflating: data/images/train/000000467511.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000467511.jpg  \n",
            "  inflating: data/images/train/000000150638.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000150638.jpg  \n",
            "  inflating: data/images/train/000000171190.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000171190.jpg  \n",
            "  inflating: data/images/train/000000305695.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000305695.jpg  \n",
            "  inflating: data/images/train/000000148739.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000148739.jpg  \n",
            "  inflating: data/images/train/000000106330.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000106330.jpg  \n",
            "  inflating: data/images/train/000000167902.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000167902.jpg  \n",
            "  inflating: data/images/train/000000013729.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000013729.jpg  \n",
            "  inflating: data/images/train/000000426203.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000426203.jpg  \n",
            "  inflating: data/images/train/000000032081.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000032081.jpg  \n",
            "  inflating: data/images/train/000000217285.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000217285.jpg  \n",
            "  inflating: data/images/train/000000259854.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000259854.jpg  \n",
            "  inflating: data/images/train/000000226058.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000226058.jpg  \n",
            "  inflating: data/images/train/000000539445.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000539445.jpg  \n",
            "  inflating: data/images/train/000000499181.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000499181.jpg  \n",
            "  inflating: data/images/train/000000382088.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000382088.jpg  \n",
            "  inflating: data/images/train/000000052007.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000052007.jpg  \n",
            "  inflating: data/images/train/000000315492.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000315492.jpg  \n",
            "  inflating: data/images/train/000000560256.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000560256.jpg  \n",
            "  inflating: data/images/train/000000210273.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000210273.jpg  \n",
            "  inflating: data/images/train/000000206411.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000206411.jpg  \n",
            "  inflating: data/images/train/000000194875.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000194875.jpg  \n",
            "  inflating: data/images/train/000000413247.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000413247.jpg  \n",
            "  inflating: data/images/train/000000201418.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000201418.jpg  \n",
            "  inflating: data/images/train/000000390301.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000390301.jpg  \n",
            "  inflating: data/images/train/000000371699.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000371699.jpg  \n",
            "  inflating: data/images/train/000000137106.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000137106.jpg  \n",
            "  inflating: data/images/train/000000114907.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000114907.jpg  \n",
            "  inflating: data/images/train/000000304560.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000304560.jpg  \n",
            "  inflating: data/images/train/000000508101.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000508101.jpg  \n",
            "  inflating: data/images/train/000000313034.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000313034.jpg  \n",
            "  inflating: data/images/train/000000198915.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000198915.jpg  \n",
            "  inflating: data/images/train/000000442746.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000442746.jpg  \n",
            "  inflating: data/images/train/000000185950.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000185950.jpg  \n",
            "  inflating: data/images/train/000000331280.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000331280.jpg  \n",
            "  inflating: data/images/train/000000213035.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213035.jpg  \n",
            "  inflating: data/images/train/000000280891.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000280891.jpg  \n",
            "  inflating: data/images/train/000000544444.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000544444.jpg  \n",
            "  inflating: data/images/train/000000438955.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000438955.jpg  \n",
            "  inflating: data/images/train/000000315450.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000315450.jpg  \n",
            "  inflating: data/images/train/000000388215.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000388215.jpg  \n",
            "  inflating: data/images/train/000000516316.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000516316.jpg  \n",
            "  inflating: data/images/train/000000039670.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000039670.jpg  \n",
            "  inflating: data/images/train/000000504074.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000504074.jpg  \n",
            "  inflating: data/images/train/000000493334.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000493334.jpg  \n",
            "  inflating: data/images/train/000000420840.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000420840.jpg  \n",
            "  inflating: data/images/train/000000145591.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000145591.jpg  \n",
            "  inflating: data/images/train/000000386210.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000386210.jpg  \n",
            "  inflating: data/images/train/000000443303.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000443303.jpg  \n",
            "  inflating: data/images/train/000000548524.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000548524.jpg  \n",
            "  inflating: data/images/train/000000035062.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000035062.jpg  \n",
            "  inflating: data/images/train/000000458045.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000458045.jpg  \n",
            "  inflating: data/images/train/000000385719.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000385719.jpg  \n",
            "  inflating: data/images/train/000000448256.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000448256.jpg  \n",
            "  inflating: data/images/train/000000492758.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000492758.jpg  \n",
            "  inflating: data/images/train/000000442009.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000442009.jpg  \n",
            "  inflating: data/images/train/000000198928.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000198928.jpg  \n",
            "  inflating: data/images/train/000000340451.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000340451.jpg  \n",
            "  inflating: data/images/train/000000002157.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000002157.jpg  \n",
            "  inflating: data/images/train/000000059635.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000059635.jpg  \n",
            "  inflating: data/images/train/000000078823.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000078823.jpg  \n",
            "  inflating: data/images/train/000000569273.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000569273.jpg  \n",
            "  inflating: data/images/train/000000210299.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000210299.jpg  \n",
            "  inflating: data/images/train/000000007991.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000007991.jpg  \n",
            "  inflating: data/images/train/000000352900.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000352900.jpg  \n",
            "  inflating: data/images/train/000000359855.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000359855.jpg  \n",
            "  inflating: data/images/train/000000222559.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000222559.jpg  \n",
            "  inflating: data/images/train/000000570736.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000570736.jpg  \n",
            "  inflating: data/images/train/000000394199.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000394199.jpg  \n",
            "  inflating: data/images/train/000000309938.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000309938.jpg  \n",
            "  inflating: data/images/train/000000154339.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000154339.jpg  \n",
            "  inflating: data/images/train/000000112378.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000112378.jpg  \n",
            "  inflating: data/images/train/000000029675.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000029675.jpg  \n",
            "  inflating: data/images/train/000000205333.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000205333.jpg  \n",
            "  inflating: data/images/train/000000308165.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000308165.jpg  \n",
            "  inflating: data/images/train/000000074200.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000074200.jpg  \n",
            "  inflating: data/images/train/000000076417.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000076417.jpg  \n",
            "  inflating: data/images/train/000000218362.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000218362.jpg  \n",
            "  inflating: data/images/train/000000523811.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000523811.jpg  \n",
            "  inflating: data/images/train/000000136033.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000136033.jpg  \n",
            "  inflating: data/images/train/000000129113.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000129113.jpg  \n",
            "  inflating: data/images/train/000000060507.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060507.jpg  \n",
            "  inflating: data/images/train/000000122046.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000122046.jpg  \n",
            "  inflating: data/images/train/000000059386.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000059386.jpg  \n",
            "  inflating: data/images/train/000000221291.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000221291.jpg  \n",
            "  inflating: data/images/train/000000488270.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000488270.jpg  \n",
            "  inflating: data/images/train/000000519569.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000519569.jpg  \n",
            "  inflating: data/images/train/000000063740.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000063740.jpg  \n",
            "  inflating: data/images/train/000000476810.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000476810.jpg  \n",
            "  inflating: data/images/train/000000167240.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000167240.jpg  \n",
            "  inflating: data/images/train/000000322968.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000322968.jpg  \n",
            "  inflating: data/images/train/000000497344.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000497344.jpg  \n",
            "  inflating: data/images/train/000000509008.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000509008.jpg  \n",
            "  inflating: data/images/train/000000511647.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000511647.jpg  \n",
            "  inflating: data/images/train/000000555005.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000555005.jpg  \n",
            "  inflating: data/images/train/000000271471.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000271471.jpg  \n",
            "  inflating: data/images/train/000000112634.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000112634.jpg  \n",
            "  inflating: data/images/train/000000156076.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000156076.jpg  \n",
            "  inflating: data/images/train/000000431568.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000431568.jpg  \n",
            "  inflating: data/images/train/000000290843.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000290843.jpg  \n",
            "  inflating: data/images/train/000000377000.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000377000.jpg  \n",
            "  inflating: data/images/train/000000190637.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000190637.jpg  \n",
            "  inflating: data/images/train/000000144300.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000144300.jpg  \n",
            "  inflating: data/images/train/000000376478.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000376478.jpg  \n",
            "  inflating: data/images/train/000000101884.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000101884.jpg  \n",
            "  inflating: data/images/train/000000252294.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000252294.jpg  \n",
            "  inflating: data/images/train/000000461405.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000461405.jpg  \n",
            "  inflating: data/images/train/000000354829.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000354829.jpg  \n",
            "  inflating: data/images/train/000000239347.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000239347.jpg  \n",
            "  inflating: data/images/train/000000569059.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000569059.jpg  \n",
            "  inflating: data/images/train/000000376322.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000376322.jpg  \n",
            "  inflating: data/images/train/000000525247.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000525247.jpg  \n",
            "  inflating: data/images/train/000000170099.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000170099.jpg  \n",
            "  inflating: data/images/train/000000491090.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000491090.jpg  \n",
            "  inflating: data/images/train/000000172856.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000172856.jpg  \n",
            "  inflating: data/images/train/000000473015.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000473015.jpg  \n",
            "  inflating: data/images/train/000000139260.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000139260.jpg  \n",
            "  inflating: data/images/train/000000033759.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000033759.jpg  \n",
            "  inflating: data/images/train/000000361919.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000361919.jpg  \n",
            "  inflating: data/images/train/000000378284.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000378284.jpg  \n",
            "  inflating: data/images/train/000000327780.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000327780.jpg  \n",
            "  inflating: data/images/train/000000471789.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000471789.jpg  \n",
            "  inflating: data/images/train/000000357501.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000357501.jpg  \n",
            "  inflating: data/images/train/000000115946.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000115946.jpg  \n",
            "  inflating: data/images/train/000000076211.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000076211.jpg  \n",
            "  inflating: data/images/train/000000423971.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000423971.jpg  \n",
            "  inflating: data/images/train/000000106912.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000106912.jpg  \n",
            "  inflating: data/images/train/000000363840.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000363840.jpg  \n",
            "  inflating: data/images/train/000000299720.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000299720.jpg  \n",
            "  inflating: data/images/train/000000046463.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000046463.jpg  \n",
            "  inflating: data/images/train/000000044260.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000044260.jpg  \n",
            "  inflating: data/images/train/000000576031.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000576031.jpg  \n",
            "  inflating: data/images/train/000000375763.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000375763.jpg  \n",
            "  inflating: data/images/train/000000047769.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000047769.jpg  \n",
            "  inflating: data/images/train/000000197004.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000197004.jpg  \n",
            "  inflating: data/images/train/000000181666.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000181666.jpg  \n",
            "  inflating: data/images/train/000000468233.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000468233.jpg  \n",
            "  inflating: data/images/train/000000521141.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000521141.jpg  \n",
            "  inflating: data/images/train/000000427256.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000427256.jpg  \n",
            "  inflating: data/images/train/000000532129.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000532129.jpg  \n",
            "  inflating: data/images/train/000000256192.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000256192.jpg  \n",
            "  inflating: data/images/train/000000512776.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000512776.jpg  \n",
            "  inflating: data/images/train/000000244019.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000244019.jpg  \n",
            "  inflating: data/images/train/000000080949.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000080949.jpg  \n",
            "  inflating: data/images/train/000000290248.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000290248.jpg  \n",
            "  inflating: data/images/train/000000024027.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000024027.jpg  \n",
            "  inflating: data/images/train/000000409424.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000409424.jpg  \n",
            "  inflating: data/images/train/000000367818.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000367818.jpg  \n",
            "  inflating: data/images/train/000000515025.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000515025.jpg  \n",
            "  inflating: data/images/train/000000064359.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000064359.jpg  \n",
            "  inflating: data/images/train/000000167122.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000167122.jpg  \n",
            "  inflating: data/images/train/000000171740.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000171740.jpg  \n",
            "  inflating: data/images/train/000000200667.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000200667.jpg  \n",
            "  inflating: data/images/train/000000572900.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000572900.jpg  \n",
            "  inflating: data/images/train/000000417632.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000417632.jpg  \n",
            "  inflating: data/images/train/000000135670.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000135670.jpg  \n",
            "  inflating: data/images/train/000000404128.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000404128.jpg  \n",
            "  inflating: data/images/train/000000312263.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000312263.jpg  \n",
            "  inflating: data/images/train/000000133567.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000133567.jpg  \n",
            "  inflating: data/images/train/000000356347.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000356347.jpg  \n",
            "  inflating: data/images/train/000000449996.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000449996.jpg  \n",
            "  inflating: data/images/train/000000365766.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000365766.jpg  \n",
            "  inflating: data/images/train/000000230983.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000230983.jpg  \n",
            "  inflating: data/images/train/000000520707.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000520707.jpg  \n",
            "  inflating: data/images/train/000000436617.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000436617.jpg  \n",
            "  inflating: data/images/train/000000119365.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000119365.jpg  \n",
            "  inflating: data/images/train/000000313182.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000313182.jpg  \n",
            "  inflating: data/images/train/000000292488.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000292488.jpg  \n",
            "  inflating: data/images/train/000000051309.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000051309.jpg  \n",
            "  inflating: data/images/train/000000426376.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000426376.jpg  \n",
            "  inflating: data/images/train/000000578236.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000578236.jpg  \n",
            "  inflating: data/images/train/000000321118.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000321118.jpg  \n",
            "  inflating: data/images/train/000000364322.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000364322.jpg  \n",
            "  inflating: data/images/train/000000061584.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000061584.jpg  \n",
            "  inflating: data/images/train/000000008532.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000008532.jpg  \n",
            "  inflating: data/images/train/000000422886.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000422886.jpg  \n",
            "  inflating: data/images/train/000000352684.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000352684.jpg  \n",
            "  inflating: data/images/train/000000117374.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000117374.jpg  \n",
            "  inflating: data/images/train/000000248810.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000248810.jpg  \n",
            "  inflating: data/images/train/000000434996.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000434996.jpg  \n",
            "  inflating: data/images/train/000000226111.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000226111.jpg  \n",
            "  inflating: data/images/train/000000280918.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000280918.jpg  \n",
            "  inflating: data/images/train/000000105014.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000105014.jpg  \n",
            "  inflating: data/images/train/000000213816.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213816.jpg  \n",
            "  inflating: data/images/train/000000116068.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000116068.jpg  \n",
            "  inflating: data/images/train/000000219485.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000219485.jpg  \n",
            "  inflating: data/images/train/000000155145.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000155145.jpg  \n",
            "  inflating: data/images/train/000000018737.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000018737.jpg  \n",
            "  inflating: data/images/train/000000179487.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000179487.jpg  \n",
            "  inflating: data/images/train/000000144706.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000144706.jpg  \n",
            "  inflating: data/images/train/000000149222.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000149222.jpg  \n",
            "  inflating: data/images/train/000000280930.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000280930.jpg  \n",
            "  inflating: data/images/train/000000520077.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000520077.jpg  \n",
            "  inflating: data/images/train/000000293794.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000293794.jpg  \n",
            "  inflating: data/images/train/000000155179.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000155179.jpg  \n",
            "  inflating: data/images/train/000000359937.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000359937.jpg  \n",
            "  inflating: data/images/train/000000300842.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000300842.jpg  \n",
            "  inflating: data/images/train/000000080022.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000080022.jpg  \n",
            "  inflating: data/images/train/000000071756.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000071756.jpg  \n",
            "  inflating: data/images/train/000000007818.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000007818.jpg  \n",
            "  inflating: data/images/train/000000309655.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000309655.jpg  \n",
            "  inflating: data/images/train/000000281409.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000281409.jpg  \n",
            "  inflating: data/images/train/000000304365.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000304365.jpg  \n",
            "  inflating: data/images/train/000000415741.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000415741.jpg  \n",
            "  inflating: data/images/train/000000082812.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000082812.jpg  \n",
            "  inflating: data/images/train/000000502229.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000502229.jpg  \n",
            "  inflating: data/images/train/000000181499.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000181499.jpg  \n",
            "  inflating: data/images/train/000000463199.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000463199.jpg  \n",
            "  inflating: data/images/train/000000178982.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000178982.jpg  \n",
            "  inflating: data/images/train/000000542625.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000542625.jpg  \n",
            "  inflating: data/images/train/000000391140.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000391140.jpg  \n",
            "  inflating: data/images/train/000000546325.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000546325.jpg  \n",
            "  inflating: data/images/train/000000170474.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000170474.jpg  \n",
            "  inflating: data/images/train/000000554735.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000554735.jpg  \n",
            "  inflating: data/images/train/000000178028.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000178028.jpg  \n",
            "  inflating: data/images/train/000000245311.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000245311.jpg  \n",
            "  inflating: data/images/train/000000255664.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000255664.jpg  \n",
            "  inflating: data/images/train/000000300659.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000300659.jpg  \n",
            "  inflating: data/images/train/000000327769.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000327769.jpg  \n",
            "  inflating: data/images/train/000000461573.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000461573.jpg  \n",
            "  inflating: data/images/train/000000038829.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000038829.jpg  \n",
            "  inflating: data/images/train/000000217872.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000217872.jpg  \n",
            "  inflating: data/images/train/000000322163.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000322163.jpg  \n",
            "  inflating: data/images/train/000000537053.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000537053.jpg  \n",
            "  inflating: data/images/train/000000058111.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000058111.jpg  \n",
            "  inflating: data/images/train/000000275749.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000275749.jpg  \n",
            "  inflating: data/images/train/000000011511.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000011511.jpg  \n",
            "  inflating: data/images/train/000000336658.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000336658.jpg  \n",
            "  inflating: data/images/train/000000287291.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000287291.jpg  \n",
            "  inflating: data/images/train/000000570456.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000570456.jpg  \n",
            "  inflating: data/images/train/000000199771.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000199771.jpg  \n",
            "  inflating: data/images/train/000000196442.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000196442.jpg  \n",
            "  inflating: data/images/train/000000125850.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000125850.jpg  \n",
            "  inflating: data/images/train/000000061960.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000061960.jpg  \n",
            "  inflating: data/images/train/000000006723.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000006723.jpg  \n",
            "  inflating: data/images/train/000000004134.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000004134.jpg  \n",
            "  inflating: data/images/train/000000283785.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000283785.jpg  \n",
            "  inflating: data/images/train/000000358195.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000358195.jpg  \n",
            "  inflating: data/images/train/000000393569.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000393569.jpg  \n",
            "  inflating: data/images/train/000000394206.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000394206.jpg  \n",
            "  inflating: data/images/train/000000061747.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000061747.jpg  \n",
            "  inflating: data/images/train/000000281179.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000281179.jpg  \n",
            "  inflating: data/images/train/000000401244.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000401244.jpg  \n",
            "  inflating: data/images/train/000000360393.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000360393.jpg  \n",
            "  inflating: data/images/train/000000401250.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000401250.jpg  \n",
            "  inflating: data/images/train/000000458325.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000458325.jpg  \n",
            "  inflating: data/images/train/000000071226.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000071226.jpg  \n",
            "  inflating: data/images/train/000000530099.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000530099.jpg  \n",
            "  inflating: data/images/train/000000419379.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000419379.jpg  \n",
            "  inflating: data/images/train/000000492362.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000492362.jpg  \n",
            "  inflating: data/images/train/000000025139.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000025139.jpg  \n",
            "  inflating: data/images/train/000000206994.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000206994.jpg  \n",
            "  inflating: data/images/train/000000497568.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000497568.jpg  \n",
            "  inflating: data/images/train/000000402765.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000402765.jpg  \n",
            "  inflating: data/images/train/000000243204.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000243204.jpg  \n",
            "  inflating: data/images/train/000000002592.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000002592.jpg  \n",
            "  inflating: data/images/train/000000409630.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000409630.jpg  \n",
            "  inflating: data/images/train/000000134034.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000134034.jpg  \n",
            "  inflating: data/images/train/000000048504.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000048504.jpg  \n",
            "  inflating: data/images/train/000000083113.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000083113.jpg  \n",
            "  inflating: data/images/train/000000479248.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000479248.jpg  \n",
            "  inflating: data/images/train/000000405195.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000405195.jpg  \n",
            "  inflating: data/images/train/000000145020.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000145020.jpg  \n",
            "  inflating: data/images/train/000000465675.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000465675.jpg  \n",
            "  inflating: data/images/train/000000384808.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000384808.jpg  \n",
            "  inflating: data/images/train/000000183675.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000183675.jpg  \n",
            "  inflating: data/images/train/000000085576.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000085576.jpg  \n",
            "  inflating: data/images/train/000000063965.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000063965.jpg  \n",
            "  inflating: data/images/train/000000081738.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000081738.jpg  \n",
            "  inflating: data/images/train/000000293390.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000293390.jpg  \n",
            "  inflating: data/images/train/000000210099.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000210099.jpg  \n",
            "  inflating: data/images/train/000000469067.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000469067.jpg  \n",
            "  inflating: data/images/train/000000002431.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000002431.jpg  \n",
            "  inflating: data/images/train/000000080340.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000080340.jpg  \n",
            "  inflating: data/images/train/000000482978.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000482978.jpg  \n",
            "  inflating: data/images/train/000000157418.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000157418.jpg  \n",
            "  inflating: data/images/train/000000258793.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000258793.jpg  \n",
            "  inflating: data/images/train/000000520301.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000520301.jpg  \n",
            "  inflating: data/images/train/000000310072.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000310072.jpg  \n",
            "  inflating: data/images/train/000000078404.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000078404.jpg  \n",
            "  inflating: data/images/train/000000214200.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000214200.jpg  \n",
            "  inflating: data/images/train/000000065455.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000065455.jpg  \n",
            "  inflating: data/images/train/000000435081.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000435081.jpg  \n",
            "  inflating: data/images/train/000000389451.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000389451.jpg  \n",
            "  inflating: data/images/train/000000525286.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000525286.jpg  \n",
            "  inflating: data/images/train/000000275198.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000275198.jpg  \n",
            "  inflating: data/images/train/000000333697.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000333697.jpg  \n",
            "  inflating: data/images/train/000000215644.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000215644.jpg  \n",
            "  inflating: data/images/train/000000523807.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000523807.jpg  \n",
            "  inflating: data/images/train/000000212895.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000212895.jpg  \n",
            "  inflating: data/images/train/000000003934.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000003934.jpg  \n",
            "  inflating: data/images/train/000000110784.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000110784.jpg  \n",
            "  inflating: data/images/train/000000213547.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000213547.jpg  \n",
            "  inflating: data/images/train/000000347664.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000347664.jpg  \n",
            "  inflating: data/images/train/000000244379.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000244379.jpg  \n",
            "  inflating: data/images/train/000000449406.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000449406.jpg  \n",
            "  inflating: data/images/train/000000180383.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000180383.jpg  \n",
            "  inflating: data/images/train/000000242287.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000242287.jpg  \n",
            "  inflating: data/images/train/000000243199.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000243199.jpg  \n",
            "  inflating: data/images/train/000000351589.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000351589.jpg  \n",
            "  inflating: data/images/train/000000262631.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000262631.jpg  \n",
            "  inflating: data/images/train/000000224664.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000224664.jpg  \n",
            "  inflating: data/images/train/000000389684.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000389684.jpg  \n",
            "  inflating: data/images/train/000000050149.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000050149.jpg  \n",
            "  inflating: data/images/train/000000219283.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000219283.jpg  \n",
            "  inflating: data/images/train/000000404923.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000404923.jpg  \n",
            "  inflating: data/images/train/000000568147.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000568147.jpg  \n",
            "  inflating: data/images/train/000000221708.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000221708.jpg  \n",
            "  inflating: data/images/train/000000437331.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000437331.jpg  \n",
            "  inflating: data/images/train/000000088250.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000088250.jpg  \n",
            "  inflating: data/images/train/000000045550.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000045550.jpg  \n",
            "  inflating: data/images/train/000000520659.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000520659.jpg  \n",
            "  inflating: data/images/train/000000293804.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000293804.jpg  \n",
            "  inflating: data/images/train/000000466156.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000466156.jpg  \n",
            "  inflating: data/images/train/000000144114.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000144114.jpg  \n",
            "  inflating: data/images/train/000000443498.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000443498.jpg  \n",
            "  inflating: data/images/train/000000246963.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000246963.jpg  \n",
            "  inflating: data/images/train/000000393838.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000393838.jpg  \n",
            "  inflating: data/images/train/000000291791.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000291791.jpg  \n",
            "  inflating: data/images/train/000000184324.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000184324.jpg  \n",
            "  inflating: data/images/train/000000294831.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000294831.jpg  \n",
            "  inflating: data/images/train/000000231527.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000231527.jpg  \n",
            "  inflating: data/images/train/000000009772.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000009772.jpg  \n",
            "  inflating: data/images/train/000000044699.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000044699.jpg  \n",
            "  inflating: data/images/train/000000511453.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000511453.jpg  \n",
            "  inflating: data/images/train/000000364297.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000364297.jpg  \n",
            "  inflating: data/images/train/000000344621.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000344621.jpg  \n",
            "  inflating: data/images/train/000000210502.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000210502.jpg  \n",
            "  inflating: data/images/train/000000405432.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000405432.jpg  \n",
            "  inflating: data/images/train/000000138550.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000138550.jpg  \n",
            "  inflating: data/images/train/000000511321.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000511321.jpg  \n",
            "  inflating: data/images/train/000000267946.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000267946.jpg  \n",
            "  inflating: data/images/train/000000186282.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186282.jpg  \n",
            "  inflating: data/images/train/000000577932.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000577932.jpg  \n",
            "  inflating: data/images/train/000000533816.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000533816.jpg  \n",
            "  inflating: data/images/train/000000425906.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000425906.jpg  \n",
            "  inflating: data/images/train/000000254368.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000254368.jpg  \n",
            "  inflating: data/images/train/000000580410.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000580410.jpg  \n",
            "  inflating: data/images/train/000000389109.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000389109.jpg  \n",
            "  inflating: data/images/train/000000490171.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000490171.jpg  \n",
            "  inflating: data/images/train/000000186296.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186296.jpg  \n",
            "  inflating: data/images/train/000000550426.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000550426.jpg  \n",
            "  inflating: data/images/train/000000173008.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000173008.jpg  \n",
            "  inflating: data/images/train/000000011699.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000011699.jpg  \n",
            "  inflating: data/images/train/000000201426.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000201426.jpg  \n",
            "  inflating: data/images/train/000000500211.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500211.jpg  \n",
            "  inflating: data/images/train/000000124636.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000124636.jpg  \n",
            "  inflating: data/images/train/000000061418.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000061418.jpg  \n",
            "  inflating: data/images/train/000000024144.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000024144.jpg  \n",
            "  inflating: data/images/train/000000504711.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000504711.jpg  \n",
            "  inflating: data/images/train/000000417779.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000417779.jpg  \n",
            "  inflating: data/images/train/000000064574.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000064574.jpg  \n",
            "  inflating: data/images/train/000000269942.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000269942.jpg  \n",
            "  inflating: data/images/train/000000446522.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000446522.jpg  \n",
            "  inflating: data/images/train/000000536947.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000536947.jpg  \n",
            "  inflating: data/images/train/000000139883.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000139883.jpg  \n",
            "  inflating: data/images/train/000000543300.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000543300.jpg  \n",
            "  inflating: data/images/train/000000109798.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000109798.jpg  \n",
            "  inflating: data/images/train/000000378873.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000378873.jpg  \n",
            "  inflating: data/images/train/000000056288.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000056288.jpg  \n",
            "  inflating: data/images/train/000000302107.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000302107.jpg  \n",
            "  inflating: data/images/train/000000484893.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000484893.jpg  \n",
            "  inflating: data/images/train/000000250127.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000250127.jpg  \n",
            "  inflating: data/images/train/000000440184.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000440184.jpg  \n",
            "  inflating: data/images/train/000000273715.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000273715.jpg  \n",
            "  inflating: data/images/train/000000370208.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000370208.jpg  \n",
            "  inflating: data/images/train/000000037689.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000037689.jpg  \n",
            "  inflating: data/images/train/000000274708.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000274708.jpg  \n",
            "  inflating: data/images/train/000000562443.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000562443.jpg  \n",
            "  inflating: data/images/train/000000534605.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000534605.jpg  \n",
            "  inflating: data/images/train/000000492968.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000492968.jpg  \n",
            "  inflating: data/images/train/000000203580.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000203580.jpg  \n",
            "  inflating: data/images/train/000000311190.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000311190.jpg  \n",
            "  inflating: data/images/train/000000368335.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000368335.jpg  \n",
            "  inflating: data/images/train/000000271116.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000271116.jpg  \n",
            "  inflating: data/images/train/000000404922.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000404922.jpg  \n",
            "  inflating: data/images/train/000000374052.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000374052.jpg  \n",
            "  inflating: data/images/train/000000032901.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000032901.jpg  \n",
            "  inflating: data/images/train/000000572678.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000572678.jpg  \n",
            "  inflating: data/images/train/000000148707.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000148707.jpg  \n",
            "  inflating: data/images/train/000000428562.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000428562.jpg  \n",
            "  inflating: data/images/train/000000534639.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000534639.jpg  \n",
            "  inflating: data/images/train/000000296969.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000296969.jpg  \n",
            "  inflating: data/images/train/000000369771.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000369771.jpg  \n",
            "  inflating: data/images/train/000000165681.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000165681.jpg  \n",
            "  inflating: data/images/train/000000472678.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000472678.jpg  \n",
            "  inflating: data/images/train/000000438017.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000438017.jpg  \n",
            "  inflating: data/images/train/000000573943.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000573943.jpg  \n",
            "  inflating: data/images/train/000000100582.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000100582.jpg  \n",
            "  inflating: data/images/train/000000205324.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000205324.jpg  \n",
            "  inflating: data/images/train/000000474786.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000474786.jpg  \n",
            "  inflating: data/images/train/000000188906.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000188906.jpg  \n",
            "  inflating: data/images/train/000000291551.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000291551.jpg  \n",
            "  inflating: data/images/train/000000553339.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000553339.jpg  \n",
            "  inflating: data/images/train/000000512403.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000512403.jpg  \n",
            "  inflating: data/images/train/000000565853.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000565853.jpg  \n",
            "  inflating: data/images/train/000000202339.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000202339.jpg  \n",
            "  inflating: data/images/train/000000506310.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000506310.jpg  \n",
            "  inflating: data/images/train/000000304984.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000304984.jpg  \n",
            "  inflating: data/images/train/000000008690.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000008690.jpg  \n",
            "  inflating: data/images/train/000000535094.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000535094.jpg  \n",
            "  inflating: data/images/train/000000515350.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000515350.jpg  \n",
            "  inflating: data/images/train/000000555012.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000555012.jpg  \n",
            "  inflating: data/images/train/000000404249.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000404249.jpg  \n",
            "  inflating: data/images/train/000000569700.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000569700.jpg  \n",
            "  inflating: data/images/train/000000016451.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000016451.jpg  \n",
            "  inflating: data/images/train/000000102356.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000102356.jpg  \n",
            "  inflating: data/images/train/000000494869.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000494869.jpg  \n",
            "  inflating: data/images/train/000000420472.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000420472.jpg  \n",
            "  inflating: data/images/train/000000183648.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000183648.jpg  \n",
            "  inflating: data/images/train/000000371472.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000371472.jpg  \n",
            "  inflating: data/images/train/000000017029.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000017029.jpg  \n",
            "  inflating: data/images/train/000000311392.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000311392.jpg  \n",
            "  inflating: data/images/train/000000126592.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000126592.jpg  \n",
            "  inflating: data/images/train/000000186042.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000186042.jpg  \n",
            "  inflating: data/images/train/000000381971.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000381971.jpg  \n",
            "  inflating: data/images/train/000000234660.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000234660.jpg  \n",
            "  inflating: data/images/train/000000116479.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000116479.jpg  \n",
            "  inflating: data/images/train/000000279774.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000279774.jpg  \n",
            "  inflating: data/images/train/000000507797.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000507797.jpg  \n",
            "  inflating: data/images/train/000000007574.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000007574.jpg  \n",
            "  inflating: data/images/train/000000119038.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000119038.jpg  \n",
            "  inflating: data/images/train/000000437898.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000437898.jpg  \n",
            "  inflating: data/images/train/000000232563.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000232563.jpg  \n",
            "  inflating: data/images/train/000000393226.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000393226.jpg  \n",
            "  inflating: data/images/train/000000179653.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000179653.jpg  \n",
            "  inflating: data/images/train/000000164602.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000164602.jpg  \n",
            "  inflating: data/images/train/000000002587.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000002587.jpg  \n",
            "  inflating: data/images/train/000000161008.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000161008.jpg  \n",
            "  inflating: data/images/train/000000253002.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000253002.jpg  \n",
            "  inflating: data/images/train/000000133000.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000133000.jpg  \n",
            "  inflating: data/images/train/000000123213.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000123213.jpg  \n",
            "  inflating: data/images/train/000000501523.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000501523.jpg  \n",
            "  inflating: data/images/train/000000426836.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000426836.jpg  \n",
            "  inflating: data/images/train/000000054931.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000054931.jpg  \n",
            "  inflating: data/images/train/000000523782.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000523782.jpg  \n",
            "  inflating: data/images/train/000000545407.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000545407.jpg  \n",
            "  inflating: data/images/train/000000170893.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000170893.jpg  \n",
            "  inflating: data/images/train/000000078565.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000078565.jpg  \n",
            "  inflating: data/images/train/000000491130.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000491130.jpg  \n",
            "  inflating: data/images/train/000000578792.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000578792.jpg  \n",
            "  inflating: data/images/train/000000430073.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000430073.jpg  \n",
            "  inflating: data/images/train/000000471991.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000471991.jpg  \n",
            "  inflating: data/images/train/000000378244.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000378244.jpg  \n",
            "  inflating: data/images/train/000000500826.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000500826.jpg  \n",
            "  inflating: data/images/train/000000093261.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000093261.jpg  \n",
            "  inflating: data/images/train/000000326462.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000326462.jpg  \n",
            "  inflating: data/images/train/000000309495.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000309495.jpg  \n",
            "  inflating: data/images/train/000000140987.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000140987.jpg  \n",
            "  inflating: data/images/train/000000322610.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000322610.jpg  \n",
            "  inflating: data/images/train/000000133969.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000133969.jpg  \n",
            "  inflating: data/images/train/000000352491.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000352491.jpg  \n",
            "  inflating: data/images/train/000000172935.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000172935.jpg  \n",
            "  inflating: data/images/train/000000523033.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000523033.jpg  \n",
            "  inflating: data/images/train/000000167486.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000167486.jpg  \n",
            "  inflating: data/images/train/000000160666.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000160666.jpg  \n",
            "  inflating: data/images/train/000000180792.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000180792.jpg  \n",
            "  inflating: data/images/train/000000358427.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000358427.jpg  \n",
            "  inflating: data/images/train/000000403122.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000403122.jpg  \n",
            "  inflating: data/images/train/000000314177.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000314177.jpg  \n",
            "  inflating: data/images/train/000000171757.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000171757.jpg  \n",
            "  inflating: data/images/train/000000512985.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000512985.jpg  \n",
            "  inflating: data/images/train/000000065736.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000065736.jpg  \n",
            "  inflating: data/images/train/000000135673.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000135673.jpg  \n",
            "  inflating: data/images/train/000000114871.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000114871.jpg  \n",
            "  inflating: data/images/train/000000082807.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000082807.jpg  \n",
            "  inflating: data/images/train/000000127263.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000127263.jpg  \n",
            "  inflating: data/images/train/000000483050.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000483050.jpg  \n",
            "  inflating: data/images/train/000000354547.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000354547.jpg  \n",
            "  inflating: data/images/train/000000221872.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000221872.jpg  \n",
            "  inflating: data/images/train/000000189775.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000189775.jpg  \n",
            "  inflating: data/images/train/000000338304.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000338304.jpg  \n",
            "  inflating: data/images/train/000000194724.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000194724.jpg  \n",
            "  inflating: data/images/train/000000328117.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000328117.jpg  \n",
            "  inflating: data/images/train/000000089761.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000089761.jpg  \n",
            "  inflating: data/images/train/000000180751.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000180751.jpg  \n",
            "  inflating: data/images/train/000000143068.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000143068.jpg  \n",
            "  inflating: data/images/train/000000055150.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000055150.jpg  \n",
            "  inflating: data/images/train/000000356387.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000356387.jpg  \n",
            "  inflating: data/images/train/000000473406.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000473406.jpg  \n",
            "  inflating: data/images/train/000000173183.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000173183.jpg  \n",
            "  inflating: data/images/train/000000506933.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000506933.jpg  \n",
            "  inflating: data/images/train/000000229221.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000229221.jpg  \n",
            "  inflating: data/images/train/000000060855.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000060855.jpg  \n",
            "  inflating: data/images/train/000000005001.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000005001.jpg  \n",
            "  inflating: data/images/train/000000467315.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000467315.jpg  \n",
            "  inflating: data/images/train/000000032861.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000032861.jpg  \n",
            "  inflating: data/images/train/000000229553.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000229553.jpg  \n",
            "  inflating: data/images/train/000000491497.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000491497.jpg  \n",
            "  inflating: data/images/train/000000264335.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000264335.jpg  \n",
            "  inflating: data/images/train/000000502599.jpg  \n",
            "  inflating: __MACOSX/data/images/train/._000000502599.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-19T03:32:54.116367Z",
          "start_time": "2024-11-19T03:32:54.114088Z"
        },
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "from tqdm import trange, tqdm\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from models.stegastamp_wm import StegaStampDecoder, StegaStampEncoder\n",
        "import collections\n",
        "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor,AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8f703baf49f7c115",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-19T03:32:07.703975Z",
          "start_time": "2024-11-19T03:32:07.273226Z"
        },
        "id": "8f703baf49f7c115",
        "outputId": "2e2da41c-ac4e-497e-8763-05c1305e5f18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.06s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "DATASET_SIZE = 1000\n",
        "IMAGE_SIZE = 256\n",
        "NUM_BITS = 48\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "coco_dataset = datasets.CocoCaptions(root = './data/images/train',\n",
        "                        annFile = './data/annotations/train_captions.json',\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.Resize(IMAGE_SIZE),\n",
        "                            transforms.CenterCrop(IMAGE_SIZE),\n",
        "                            transforms.ToTensor()\n",
        "                        ]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4261a76a11128fa5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-19T03:18:12.503290Z",
          "start_time": "2024-11-19T03:18:12.454232Z"
        },
        "id": "4261a76a11128fa5",
        "outputId": "938fa67c-0292-40ef-ec54-c299d4dea83e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StegaStampDecoder(\n",
              "  (decoder): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (9): ReLU()\n",
              "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (11): ReLU()\n",
              "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (13): ReLU()\n",
              "  )\n",
              "  (dense): Sequential(\n",
              "    (0): Linear(in_features=8192, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=48, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "signature = torch.randint(0, 2, (1, NUM_BITS), device=device).float()\n",
        "wm_encoder = StegaStampEncoder(\n",
        "    IMAGE_SIZE,\n",
        "    IMAGE_CHANNELS,\n",
        "    NUM_BITS,\n",
        ")\n",
        "wm_encoder_load = torch.load('models/wm_stegastamp_encoder.pth', map_location=device, weights_only=True)\n",
        "if type(wm_encoder_load) is collections.OrderedDict:\n",
        "    wm_encoder.load_state_dict(wm_encoder_load)\n",
        "else:\n",
        "    wm_encoder = wm_encoder_load\n",
        "\n",
        "wm_decoder = StegaStampDecoder(\n",
        "    IMAGE_SIZE,\n",
        "    IMAGE_CHANNELS,\n",
        "    NUM_BITS,\n",
        ")\n",
        "wm_decoder_load = torch.load('models/wm_stegastamp_decoder.pth', map_location=device, weights_only=True)\n",
        "if type(wm_decoder_load) is collections.OrderedDict:\n",
        "    wm_decoder.load_state_dict(wm_decoder_load)\n",
        "else:\n",
        "    wm_encoder = wm_encoder_load\n",
        "\n",
        "wm_encoder.to(device)\n",
        "wm_decoder.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ceb8dd315210fafc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-19T03:23:14.326903Z",
          "start_time": "2024-11-19T03:23:14.323260Z"
        },
        "id": "ceb8dd315210fafc"
      },
      "outputs": [],
      "source": [
        "class CocoCaptionMixedWMDataset(Dataset):\n",
        "    def __init__(self, signature, coco_dataset, num_images):\n",
        "        super(CocoCaptionMixedWMDataset, self).__init__()\n",
        "        self.coco_dataset = coco_dataset\n",
        "        self.dataset = []\n",
        "        for i in trange(num_images):\n",
        "            try:\n",
        "                image, caption = coco_dataset[i]\n",
        "                image = image.to(device).float()\n",
        "                wm_image = wm_encoder(signature.unsqueeze(0), image.unsqueeze(0))\n",
        "                self.dataset.append((wm_image.squeeze(0), 1))\n",
        "                self.dataset.append((image, 0))\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bb221d060825ebc3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-19T03:23:16.566953Z",
          "start_time": "2024-11-19T03:23:16.436476Z"
        },
        "id": "bb221d060825ebc3",
        "outputId": "625313d7-9edf-4b08-8edd-24f48165a01e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 172/1000 [00:06<01:09, 11.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 180/1000 [00:07<00:38, 21.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 190/1000 [00:07<00:25, 32.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 201/1000 [00:07<00:19, 41.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 212/1000 [00:07<00:17, 44.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 217/1000 [00:07<00:20, 37.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 222/1000 [00:08<00:23, 33.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 231/1000 [00:08<00:22, 34.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 241/1000 [00:08<00:19, 38.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 246/1000 [00:08<00:18, 40.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 255/1000 [00:09<00:23, 31.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 259/1000 [00:09<00:23, 32.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 269/1000 [00:09<00:20, 36.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 273/1000 [00:09<00:25, 28.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 277/1000 [00:09<00:29, 24.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▊       | 286/1000 [00:10<00:25, 28.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 292/1000 [00:10<00:26, 26.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 301/1000 [00:10<00:20, 34.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 310/1000 [00:10<00:18, 36.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 314/1000 [00:10<00:19, 34.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 327/1000 [00:11<00:14, 46.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 342/1000 [00:11<00:11, 55.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 348/1000 [00:11<00:13, 50.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 354/1000 [00:11<00:14, 43.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 363/1000 [00:12<00:18, 34.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 372/1000 [00:12<00:17, 36.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 380/1000 [00:12<00:17, 34.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 385/1000 [00:12<00:16, 36.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 395/1000 [00:12<00:15, 37.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 404/1000 [00:13<00:14, 39.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████▏     | 414/1000 [00:13<00:15, 38.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 422/1000 [00:13<00:15, 36.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 432/1000 [00:13<00:13, 41.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 437/1000 [00:13<00:13, 42.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 448/1000 [00:14<00:13, 40.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 458/1000 [00:14<00:12, 43.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 469/1000 [00:14<00:11, 44.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▊     | 487/1000 [00:14<00:08, 63.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 502/1000 [00:15<00:07, 67.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 520/1000 [00:15<00:06, 74.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 536/1000 [00:15<00:06, 76.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 553/1000 [00:15<00:05, 77.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 571/1000 [00:15<00:05, 80.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 589/1000 [00:16<00:04, 82.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 598/1000 [00:16<00:04, 80.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 616/1000 [00:16<00:04, 79.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 634/1000 [00:16<00:04, 79.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 642/1000 [00:16<00:05, 69.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 657/1000 [00:17<00:05, 59.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 670/1000 [00:17<00:05, 56.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 676/1000 [00:17<00:06, 51.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 688/1000 [00:17<00:06, 50.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 699/1000 [00:18<00:06, 47.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 705/1000 [00:18<00:05, 49.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 717/1000 [00:18<00:05, 49.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 728/1000 [00:18<00:05, 48.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 740/1000 [00:18<00:05, 50.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 751/1000 [00:19<00:05, 49.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▋  | 763/1000 [00:19<00:04, 51.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 774/1000 [00:19<00:04, 48.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 784/1000 [00:19<00:04, 48.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 795/1000 [00:20<00:04, 50.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 801/1000 [00:20<00:03, 51.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 816/1000 [00:20<00:03, 61.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 832/1000 [00:20<00:02, 67.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 849/1000 [00:20<00:02, 72.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 867/1000 [00:20<00:01, 78.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 884/1000 [00:21<00:01, 79.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 902/1000 [00:21<00:01, 81.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 920/1000 [00:21<00:01, 77.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▎| 937/1000 [00:21<00:00, 79.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 955/1000 [00:22<00:00, 79.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 964/1000 [00:22<00:00, 80.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 982/1000 [00:22<00:00, 80.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:22<00:00, 44.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.42 GiB is allocated by PyTorch, and 193.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = CocoCaptionMixedWMDataset(signature, coco_dataset, DATASET_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBreggkg79l5",
        "outputId": "965dbf7a-43ba-4155-bb37-3d0fe3f6bf6c"
      },
      "id": "IBreggkg79l5",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "336"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "resnet18 = resnet18.to(device)\n",
        "resnet18.eval()\n",
        "feature_extractor = torch.nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "print(\"Loaded ResNet18 model for feature extraction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-rnIXuB4X5A",
        "outputId": "04c48270-c9ec-4738-8356-ad878c1a9dac"
      },
      "id": "w-rnIXuB4X5A",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 198MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ResNet18 model for feature extraction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "captions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, lbls, caps in tqdm(dataloader, desc=\"Extracting Features and Captions\"):\n",
        "        images = images.to(device)\n",
        "        outputs = feature_extractor(images)\n",
        "        outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, 512]\n",
        "        features.append(outputs.cpu().numpy())\n",
        "        labels.extend(lbls.numpy())\n",
        "        captions.extend(caps)\n",
        "\n",
        "features = np.concatenate(features, axis=0)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(f\"Extracted features shape: {features.shape}\")  # Expected: [2 * DATASET_SIZE, 512]\n",
        "print(f\"Labels shape: {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "ZFpbSbpD4oAS",
        "outputId": "b8e10ccf-94eb-4dc6-a68e-04fe24fe16f8"
      },
      "id": "ZFpbSbpD4oAS",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/11 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 17.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 195.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d407025c7981>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 17.06 MiB is free. Process 13172 has 14.73 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 195.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f27ccba4",
      "metadata": {
        "id": "f27ccba4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c1b6c6-4241-40ae-bb14-ac8201ba3d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 0.8235294117647058\n",
            "F1 Score: 0.9032258064516129\n"
          ]
        }
      ],
      "source": [
        "split_idx = int(len(features) * 0.8)\n",
        "X_train, X_test = features[:split_idx], features[split_idx:]\n",
        "y_train, y_test = labels[:split_idx], labels[split_idx:]\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U4i2VxShzpZq"
      },
      "id": "U4i2VxShzpZq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}